---
layout: index.njk
---

## Download and get started

In order to use Steep, you need to download it first. Choose from one of the
following options:

<div class="download-btns">
<a href="https://github.com/steep-wms/steep/releases/download/v5.0.1/steep-5.0.1.zip" class="btn btn-primary"><i data-feather="download"></i> Download Steep 5.0.1 (binaries)</a>
<a href="https://hub.docker.com/r/steep/steep/" class="btn btn-secondary">{% simpleIcon "docker" %} Docker image</a>
<a href="https://github.com/steep-wms/steep" class="btn btn-secondary"><i data-feather="github"></i> Source code</a>
</div>

If you downloaded the binary package of Steep, extract the ZIP file and run the
start script:

```bash
cd steep-5.0.1
bin/steep
```

Or, start the [Docker image](https://hub.docker.com/orgs/steep/steep) as
follows:

```bash
docker run --name steep -d --rm -p 8080:8080 \
    -e STEEP_HTTP_HOST=0.0.0.0 steep/steep:unstable
```

After a few seconds, you should be able to access Steep's web interface on
<http://localhost:8080/>.

We will now submit a simple workflow to test if Steep is running correctly. The
workflow consists of a single `sleep` command that waits for 10 seconds and
then quits. Execute the following command:

```bash
curl -X POST http://localhost:8080/workflows -d 'api: 4.0.0
vars:
  - id: sleep_seconds
    value: 10
actions:
  - type: execute
    service: sleep
    parameters:
      - id: seconds
        var: sleep_seconds'
```

The command will return the ID of the submitted workflow. You can monitor the
execution in the web interface or by issuing the following command:

```bash
curl http://localhost:8080/workflows/<workflow-id>
```

Replace `<workflow-id>` by the returned ID.

*Congratulations! You successfully installed Steep and ran your first workflow.*

## Documentation

In this section, we will describe the individual features of Steep. The
documentation always applies to the latest version.

<section id="sec-data-models">

### Data models

#### Workflows

TODO

#### Process chains

TODO

#### Submissions

A *submission* is created when you submit a [workflow](#workflows) through the
[`/workflows`](#get-submissions) endpoint. It contains information about the
workflow execution such as the start and end time as well as the current
[status](#submission-status).

| Property               | Type   | Description
| ---------------------- | ------ | -----------
| id                     | string | Unique submission identifier
| workflow               | object | The submitted [workflow](#workflows)
| startTime              | string | An ISO 8601 timestamp denoting the date and time when the workflow execution was started. May be `null` if the execution has not started yet.
| endTime                | string | An ISO 8601 timestamp denoting the date and time when the workflow execution finished. May be `null` if the execution has not finished yet.
| status                 | string | The current [status](#submission-status) of the submission
| runningProcessChains   | number | The number of [process chains](#process-chains) currently being executed
| cancelledProcessChains | number | The number of process chains that have been cancelled
| succeededProcessChains | number | The number of process chains that have finished successfully
| failedProcessChains    | number | The number of process chains whose execution has failed
| totalProcessChains     | number | The current total number of process chains in this submission. May increase during execution when new process chains are generated.
| results                | object | If `status` is `SUCCESS` or `PARTIAL_SUCCESS`, this property contains the list of workflow result files grouped by their output variable ID. Otherwise, it is `null`.
| errorMessage           | string | If `status` is `ERROR`, this property contains a human-readable error message. Otherwise, it is `null`.

{% codeExample "submission" %}
{
  "id": "aiq7eios7ubxglkcqx5a",
  "workflow": {
    "api": "4.0.0",
    "vars": [{
      "id": "myInputFile",
      "value": "/data/input.txt"
    }, {
      "id": "myOutputFile"
    }],
    "actions": [{
      "type": "execute",
      "service": "cp",
      "inputs": [{
        "id": "input_file",
        "var": "myInputFile"
      }],
      "outputs": [{
        "id": "output_file",
        "var": "myOutputFile",
        "store": true
      }],
      "parameters": []
    }]
  },
  "startTime": "2020-02-13T15:38:58.719382Z",
  "endTime": "2020-02-13T15:39:00.807715Z",
  "status": "SUCCESS",
  "runningProcessChains": 0,
  "cancelledProcessChains": 0,
  "succeededProcessChains": 1,
  "failedProcessChains": 0,
  "totalProcessChains": 1,
  "results": {
    "myOutputFile": [
      "/data/out/aiq7eios7ubxglkcqx5a/aiq7hygs7ubxglkcrf5a"
    ]
  }
}
{% endCodeExample %}

#### Submission status

The following table shows the statuses a [submission](#submissions) can have:

| Status          | Description
| --------------- | -----------
| ACCEPTED        | The submission has been accepted by Steep but execution has not started yet
| RUNNING         | The submission is currently being executed
| CANCELLED       | The submission was cancelled
| SUCCESS         | The execution of the submission finished successfully
| PARTIAL_SUCCESS | The submission was executed completely but one or more process chains failed
| ERROR           | The execution of the submission failed

#### Process chain status

The following table shows the statuses a [process chain](#process-chains) can have:

| Status          | Description
| --------------- | -----------
| REGISTERED      | The process chain has been created but execution has not started yet
| RUNNING         | The process chain is currently being executed
| CANCELLED       | The execution of the process chain was cancelled
| SUCCESS         | The process chain was executed successfully
| ERROR           | The execution of the process chain failed

#### Service metadata

TODO

#### Setups

TODO

</section>

### HTTP endpoints

#### Get submissions

### Configuration

TODO

## About

Steep's development is led by the competence center for
[Spatial Information Management](https://igd.fraunhofer.de/en/competences/technologies/spatial-information-management)
of the [Fraunhofer Institute for Computer Graphics Research IGD](https://igd.fraunhofer.de/)
in Darmstadt, Germany. *Fraunhofer IGD* is the international leading research
institution for applied visual computing. The competence center for *Spatial
Information Management* offers expertise and innovative technologies that
enable successful communication and efficient cooperation with the help of
geographic information.

*Steep* was ini­tially de­veloped within the re­search pro­ject "IQmu­lus" (A
High-volume Fu­sion and Ana­lysis Plat­form for Geo­spa­tial Point Clouds, Cov­er­ages
and Volu­met­ric Data Sets) fun­ded from the 7<sup>th</sup> Frame­work Pro­gramme of the
European Com­mis­sion, call iden­ti­fier FP7-ICT-2011-8, un­der the Grant agree­ment
no. 318787 from 2012 to 2016. It was pre­vi­ously called the 'IQmu­lus Job­Man­ager'
or just the 'Job­Man­ager'.

#### Publications

Steep and its predecessor JobManager have ap­peared in at least the fol­low­ing
pub­lic­a­tions:

<div class="research">
    <div class="research-item">
        <div class="research-image">
            <a href="https://michelkraemer.com/publications/2018/Kraemer,%20M.%20(2018).%20A%20Microservice%20Architecture%20for%20the%20Processing%20of%20Large%20Geospatial%20Data%20in%20the%20Cloud.pdf"><img src="https://michelkraemer.com/images/research/18-01.jpg" class="img-fluid"></a>
        </div>
        <div class="research-body">
            <div class="csl-bib-body">
                <div class="csl-entry">Krämer, M. (2018). <i>A Mi­croservice Ar­chi­tec­ture for the Pro­cessing of Large Geo­spa­tial Data in the Cloud</i> (Doc­toral dis­ser­ta­tion). Tech­nis­che Uni­versität Darm­stadt. <a href="https://doi.org/10.13140/RG.2.2.30034.66248">ht­tps://​doi.org/​10.13140/​RG.2.2.30034.66248</a><br>
                <span class="bib-links">[ <a href="https://michelkraemer.com/publications/2018/Kraemer,%20M.%20(2018).%20A%20Microservice%20Architecture%20for%20the%20Processing%20of%20Large%20Geospatial%20Data%20in%20the%20Cloud.pdf">PDF</a> ]</span></div>
            </div>
        </div>
    </div>
    <div class="research-item">
        <div class="research-image">
            <img src="https://michelkraemer.com/images/research/16-01.jpg" class="img-fluid">
        </div>
        <div class="research-body">
            <div class="csl-bib-body">
                <div class="csl-entry">Böhm, J., Bredif, M., Gi­er­linger, T., Krämer, M., Linden­bergh, R., Liu, K., … Sir­ma­cek, B. (2016). The IQmu­lus Urban Show­case: Auto­matic Tree Clas­si­fic­a­tion and Iden­ti­fic­a­tion in Huge Mo­bile Map­ping Point Clouds. <i>IS­PRS - In­ter­na­tional Archives of the Pho­to­gram­metry, Re­mote Sens­ing and Spa­tial In­form­a­tion Sci­ences</i>, <i>XLI</i>-<i>B3</i>, 301–307. <a href="https://doi.org/10.5194/isprs-archives-XLI-B3-301-2016">ht­tps://​doi.org/​10.5194/​is­prs-archives-XLI-B3-301-2016</a></div>
            </div>
        </div>
    </div>
    <div class="research-item">
        <div class="research-image">
            <img src="https://michelkraemer.com/images/research/15-04.jpg" class="img-fluid">
        </div>
        <div class="research-body">
            <div class="csl-bib-body">
                <div class="csl-entry">Krämer, M., &amp; Sen­ner, I. (2015). A mod­u­lar soft­ware ar­chi­tec­ture for pro­cessing of big geo­spa­tial data in the cloud. <i>Com­puters &amp; Graph­ics</i>, <i>49</i>, 69–81. <a href="https://doi.org/10.1016/j.cag.2015.02.005">ht­tps://​doi.org/​10.1016/​j.cag.2015.02.005</a></div>
            </div>
        </div>
    </div>
</div>
