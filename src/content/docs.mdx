import CodeExample from "../components/CodeExample";
import ScrollLink from "../components/ScrollLink";
import Layout from "./docs";
import "./docs.scss";

export default Layout;

## Documentation

In this section, we describe the individual features of Steep. The
documentation always applies to the latest software version.

###### Table of contents

<div className="table-of-contents"></div>

### How does Steep work?

TODO

### Example workflows

In this section, we describe example workflows covering patterns we regularly
see in real-world use cases. For each workflow, we also provide the required
service metadata. For more information about the <ScrollLink href="#workflows">workflow model</ScrollLink>
and <ScrollLink href="#service-metadata">service metadata</ScrollLink>, please read
the section on <ScrollLink href="#data-models">data models</ScrollLink>.

#### Running two services in parallel

This example workflow consists of two actions that each copy a file. Since both
actions do not depend on each other (i.e. they do not share any variable), Steep
converts them to two independent process chains and executes them in parallel
(as long as there are at least two agents available).

The workflow defines four variables. `inputFile1` and `inputFile1` point to the
two files to be copied. `outputFile1` and `outputFile2` have no value. Steep
will create unique values (output file names) for them during the workflow
execution.

The workflow then specifies two execute actions for the `copy` service. The
service metadata of `copy` defines that this processing service has an input
parameter `input_file` and an output parameter `output_file`, both of which
must be specified exactly one time (`cardinality` equals `1..1`).

For each execute action, Steep assigns the input variables to the input
parameters, generates file names for the output variables, and then executes the
processing services.

###### Workflow:

<CodeExample>

```json code-example
{
  "api": "4.0.0",
  "vars": [{
    "id": "inputFile1",
    "value": "example1.txt"
  }, {
    "id": "outputFile1"
  }, {
    "id": "inputFile2",
    "value": "example2.txt"
  }, {
    "id": "outputFile2"
  }],
  "actions": [{
    "type": "execute",
    "service": "copy",
    "inputs": [{
      "id": "input_file",
      "var": "inputFile1"
    }],
    "outputs": [{
      "id": "output_file",
      "var": "outputFile1"
    }]
  }, {
    "type": "execute",
    "service": "copy",
    "inputs": [{
      "id": "input_file",
      "var": "inputFile2"
    }],
    "outputs": [{
      "id": "output_file",
      "var": "outputFile2"
    }]
  }]
}
```

</CodeExample>

###### Service metadata:

<CodeExample>

```json code-example
[{
  "id": "copy",
  "name": "Copy",
  "description": "Copy files",
  "path": "cp",
  "runtime": "other",
  "parameters": [{
    "id": "input_file",
    "name": "Input file name",
    "description": "Input file name",
    "type": "input",
    "cardinality": "1..1",
    "data_type": "file"
  }, {
    "id": "output_file",
    "name": "Output file name",
    "description": "Output file name",
    "type": "output",
    "cardinality": "1..1",
    "data_type": "file"
  }]
}]
```

</CodeExample>

#### Chaining two services

The following example workflow makes a copy of a file and then a copy of the
copy (i.e. the file is copied and the result is copied again). The workflow
contains two actions that share the same variable: `outputFile1` is used as
the output of the first action and as the input of the second action. Steep
executes them in sequence.

The service metadata for this workflow is the same as for the previous one.

###### Workflow:

<CodeExample>

```json code-example
{
  "api": "4.0.0",
  "vars": [{
    "id": "inputFile",
    "value": "example.txt"
  }, {
    "id": "outputFile1"
  }, {
    "id": "outputFile2"
  }],
  "actions": [{
    "type": "execute",
    "service": "copy",
    "inputs": [{
      "id": "input_file",
      "var": "inputFile"
    }],
    "outputs": [{
      "id": "output_file",
      "var": "outputFile1"
    }]
  }, {
    "type": "execute",
    "service": "copy",
    "inputs": [{
      "id": "input_file",
      "var": "outputFile1"
    }],
    "outputs": [{
      "id": "output_file",
      "var": "outputFile2"
    }]
  }]
}
```

</CodeExample>

#### Splitting and joining results

This example starts with an action that copies a file. Two other actions then
run in parallel and make copies of the result of the first action. A final
action then joins these copies to a single file. The workflow has a
split-and-join pattern because the graph is split into two branches after the
first action. These branches are then joined into a single one with the final
action.

###### Workflow:

<CodeExample>

```json code-example
{
  "api": "4.0.0",
  "vars": [{
    "id": "inputFile",
    "value": "example.txt"
  }, {
    "id": "outputFile1"
  }, {
    "id": "outputFile2"
  }, {
    "id": "outputFile3"
  }, {
    "id": "outputFile4"
  }],
  "actions": [{
    "type": "execute",
    "service": "copy",
    "inputs": [{
      "id": "input_file",
      "var": "inputFile"
    }],
    "outputs": [{
      "id": "output_file",
      "var": "outputFile1"
    }]
  }, {
    "type": "execute",
    "service": "copy",
    "inputs": [{
      "id": "input_file",
      "var": "outputFile1"
    }],
    "outputs": [{
      "id": "output_file",
      "var": "outputFile2"
    }]
  }, {
    "type": "execute",
    "service": "copy",
    "inputs": [{
      "id": "input_file",
      "var": "outputFile1"
    }],
    "outputs": [{
      "id": "output_file",
      "var": "outputFile3"
    }]
  }, {
    "type": "execute",
    "service": "join",
    "inputs": [{
      "id": "i",
      "var": "outputFile2"
    }, {
      "id": "i",
      "var": "outputFile3"
    }],
    "outputs": [{
      "id": "o",
      "var": "outputFile4"
    }]
  }]
}
```

</CodeExample>

###### Service metadata:

<CodeExample>

```json code-example
[{
  "id": "copy",
  "name": "Copy",
  "description": "Copy files",
  "path": "cp",
  "runtime": "other",
  "parameters": [{
    "id": "input_file",
    "name": "Input file name",
    "description": "Input file name",
    "type": "input",
    "cardinality": "1..1",
    "data_type": "file"
  }, {
    "id": "output_file",
    "name": "Output file name",
    "description": "Output file name",
    "type": "output",
    "cardinality": "1..1",
    "data_type": "file"
  }]
}, {
  "id": "join",
  "name": "Join",
  "description": "Merge one or more files into one",
  "path": "join.sh",
  "runtime": "other",
  "parameters": [{
    "id": "i",
    "name": "Input files",
    "description": "One or more input files to merge",
    "type": "input",
    "cardinality": "1..n",
    "data_type": "file"
  }, {
    "id": "o",
    "name": "Output file",
    "description": "The output file",
    "type": "output",
    "cardinality": "1..1",
    "data_type": "file"
  }]
}]
```

</CodeExample>

#### Dynamically processing results in parallel

This example demonstrates how to process the results of an action in parallel
even if the number of result files is unknown during the design of the workflow.
The workflow starts with an action that splits an input file `inputFile` into
multiple files (e.g. one file per line) stored in a directory `outputDirectory`.
A for-each action then iterates over these files and creates copies. The
for-each action has an iterator `i` that serves as the input for the individual
instances of the `copy` service. The output files (`outputFile1`) of this service
are collected via the `yieldToOutput` property in a variable called `copies`.
The final `join` service merges these copies into a single file `outputFile2`.

###### Workflow:

<CodeExample>

```json code-example
{
  "api": "4.0.0",
  "vars": [{
    "id": "inputFile",
    "value": "example.txt"
  }, {
    "id": "lines",
    "value": 1
  }, {
    "id": "outputDirectory"
  }, {
    "id": "i"
  }, {
    "id": "outputFile1"
  }, {
    "id": "copies"
  }, {
    "id": "outputFile2"
  }],
  "actions": [{
    "type": "execute",
    "service": "split",
    "parameters": [{
      "id": "lines",
      "var": "lines"
    }],
    "inputs": [{
      "id": "file",
      "var": "inputFile"
    }],
    "outputs": [{
      "id": "output_directory",
      "var": "outputDirectory"
    }]
  }, {
    "type": "for",
    "input": "outputDirectory",
    "enumerator": "i",
    "output": "copies",
    "actions": [{
      "type": "execute",
      "service": "copy",
      "inputs": [{
        "id": "input_file",
        "var": "i"
      }],
      "outputs": [{
        "id": "output_file",
        "var": "outputFile1"
      }]
    }],
    "yieldToOutput": "outputFile1"
  }, {
    "type": "execute",
    "service": "join",
    "inputs": [{
      "id": "i",
      "var": "copies"
    }],
    "outputs": [{
      "id": "o",
      "var": "outputFile2"
    }]
  }]
}
```

</CodeExample>

###### Service metadata:

<CodeExample>

```json code-example
[{
  "id": "split",
  "name": "Split",
  "description": "Split a file into pieces",
  "path": "split",
  "runtime": "other",
  "parameters": [{
    "id": "lines",
    "name": "Number of lines per file",
    "description": "Create smaller files n lines in length",
    "type": "argument",
    "cardinality": "0..1",
    "data_type": "integer",
    "label": "-l"
  }, {
    "id": "file",
    "name": "Input file",
    "description": "The input file to split",
    "type": "input",
    "cardinality": "1..1",
    "data_type": "file"
  }, {
    "id": "output_directory",
    "name": "Output directory",
    "description": "The output directory",
    "type": "output",
    "cardinality": "1..1",
    "data_type": "directory",
    "file_suffix": "/"
  }]
}, {
  "id": "copy",
  "name": "Copy",
  "description": "Copy files",
  "path": "cp",
  "runtime": "other",
  "parameters": [{
    "id": "input_file",
    "name": "Input file name",
    "description": "Input file name",
    "type": "input",
    "cardinality": "1..1",
    "data_type": "file"
  }, {
    "id": "output_file",
    "name": "Output file name",
    "description": "Output file name",
    "type": "output",
    "cardinality": "1..1",
    "data_type": "file"
  }]
}, {
  "id": "join",
  "name": "Join",
  "description": "Merge one or more files into one",
  "path": "join.sh",
  "runtime": "other",
  "parameters": [{
    "id": "i",
    "name": "Input files",
    "description": "One or more input files to merge",
    "type": "input",
    "cardinality": "1..n",
    "data_type": "file"
  }, {
    "id": "o",
    "name": "Output file",
    "description": "The output file",
    "type": "output",
    "cardinality": "1..1",
    "data_type": "file"
  }]
}]
```

</CodeExample>

#### Feeding results back into the workflow (cycles/loops)

TODO

### Data models

#### Workflows

TODO

#### Process chains

TODO

#### Submissions

A *submission* is created when you submit a <ScrollLink href="#workflows">workflow</ScrollLink>
through the <ScrollLink href="#get-submissions">`/workflows`</ScrollLink> endpoint. It contains information
about the workflow execution such as the start and end time as well as the
current <ScrollLink href="#submission-status">status</ScrollLink>.

| Property               | Type   | Description
| ---------------------- | ------ | -----------
| id                     | string | Unique submission identifier
| workflow               | object | The submitted <ScrollLink href="#workflows">workflow</ScrollLink>
| startTime              | string | An ISO 8601 timestamp denoting the date and time when the workflow execution was started. May be `null` if the execution has not started yet.
| endTime                | string | An ISO 8601 timestamp denoting the date and time when the workflow execution finished. May be `null` if the execution has not finished yet.
| status                 | string | The current <ScrollLink href="#submission-status">status</ScrollLink> of the submission
| runningProcessChains   | number | The number of <ScrollLink href="#process-chains">process chains</ScrollLink> currently being executed
| cancelledProcessChains | number | The number of process chains that have been cancelled
| succeededProcessChains | number | The number of process chains that have finished successfully
| failedProcessChains    | number | The number of process chains whose execution has failed
| totalProcessChains     | number | The current total number of process chains in this submission. May increase during execution when new process chains are generated.
| results                | object | If `status` is `SUCCESS` or `PARTIAL_SUCCESS`, this property contains the list of workflow result files grouped by their output variable ID. Otherwise, it is `null`.
| errorMessage           | string | If `status` is `ERROR`, this property contains a human-readable error message. Otherwise, it is `null`.

<CodeExample>

```json code-example
{
  "id": "aiq7eios7ubxglkcqx5a",
  "workflow": {
    "api": "4.0.0",
    "vars": [{
      "id": "myInputFile",
      "value": "/data/input.txt"
    }, {
      "id": "myOutputFile"
    }],
    "actions": [{
      "type": "execute",
      "service": "cp",
      "inputs": [{
        "id": "input_file",
        "var": "myInputFile"
      }],
      "outputs": [{
        "id": "output_file",
        "var": "myOutputFile",
        "store": true
      }],
      "parameters": []
    }]
  },
  "startTime": "2020-02-13T15:38:58.719382Z",
  "endTime": "2020-02-13T15:39:00.807715Z",
  "status": "SUCCESS",
  "runningProcessChains": 0,
  "cancelledProcessChains": 0,
  "succeededProcessChains": 1,
  "failedProcessChains": 0,
  "totalProcessChains": 1,
  "results": {
    "myOutputFile": [
      "/data/out/aiq7eios7ubxglkcqx5a/aiq7hygs7ubxglkcrf5a"
    ]
  }
}
```

</CodeExample>

#### Submission status

The following table shows the statuses a <ScrollLink href="#submissions">submission</ScrollLink>
can have:

| Status          | Description
| --------------- | -----------
| ACCEPTED        | The submission has been accepted by Steep but execution has not started yet
| RUNNING         | The submission is currently being executed
| CANCELLED       | The submission was cancelled
| SUCCESS         | The execution of the submission finished successfully
| PARTIAL_SUCCESS | The submission was executed completely but one or more process chains failed
| ERROR           | The execution of the submission failed

#### Process chain status

The following table shows the statuses a <ScrollLink href="#process-chains">process chain</ScrollLink>
can have:

| Status          | Description
| --------------- | -----------
| REGISTERED      | The process chain has been created but execution has not started yet
| RUNNING         | The process chain is currently being executed
| CANCELLED       | The execution of the process chain was cancelled
| SUCCESS         | The process chain was executed successfully
| ERROR           | The execution of the process chain failed

#### Service metadata

Service metadata is used to describe the interface of a processing service so
it can be executed by Steep.

| Property                              | Type   | Description
| ------------------------------------- | ------ | -----------
| id<br/>*(required)*                    | string | A unique service identifier
| name<br/>*(required)*                  | string | A human-readable name
| description<br/>*(required)*           | string | A human-readable description
| path<br/>*(required)*                  | string | Relative path to the service executable in the service artefact (or a Docker image if `runtime` equals `docker`)
| runtime<br/>*(required)*               | string | The <ScrollLink href="#runtime-environments">runtime environment</ScrollLink>
| parameters<br/>*(required)*            | array  | A list of <ScrollLink href="#service-parameters">service parameters</ScrollLink>
| runtime_args<br/>*(optional)*          | array  | An optional list of <ScrollLink href="#runtime-arguments">arguments</ScrollLink> to pass to the runtime
| required_capabilities<br/>*(optional)* | array  | A set of strings specifying capabilities a host system must provide to be able to execute this service. See also <ScrollLink href="#setups">setups</ScrollLink>.

<CodeExample>

```json code-example
{
  "id": "cp",
  "name": "cp",
  "description": "Copies files",
  "path": "cp",
  "runtime": "other",
  "parameters": [{
    "id": "no_overwrite",
    "name": "No overwrite",
    "description": "Do not overwrite existing file",
    "type": "argument",
    "cardinality": "1..1",
    "label": "-n",
    "data_type": "boolean",
    "default": false
  }, {
    "id": "input_file",
    "name": "Input file name",
    "description": "Input file name",
    "type": "input",
    "cardinality": "1..1",
    "data_type": "file"
  }, {
    "id": "output_file",
    "name": "Output file name",
    "description": "Output file name",
    "type": "output",
    "cardinality": "1..1",
    "data_type": "file"
  }]
}
```

</CodeExample>

#### Runtime environments

Steep provides a set of default runtime environments that define how
processing services are executed. More environments can be added through <ScrollLink href="#custom-runtime-environments">runtime environment plugins</ScrollLink>.

| Name    | Description
| ------- | -----------
| docker  | The service will be executed through Docker. The service metadata attribute `path` specifies the Docker image to run. The attribute `runtime_args` specifies parameters that should be forwarded to the `docker` `run` command.
| other   | The service will be executed like a normal executable program (binary or shell script)

#### Service parameters

TODO

#### Runtime arguments

TODO

#### Setups

TODO

### HTTP endpoints

#### Get submissions

### Configuration

TODO

### Extending Steep through plugins

TODO

#### Custom runtime environments

TODO

#### Output adapters

TODO

#### Process chain adapters

TODO
