[{"slug":"","body":"Introduction\nChoose from one of the following options to download Steep:\nDownload Steep 6.6.0 (binaries)\nDocker image\nSource code\nIf you’ve downloaded the binary package of Steep, extract the ZIP file and run the start script:\nTerminal\nOr, start the Docker image as follows:\nTerminal\nAfter a few seconds, you can access Steep’s web interface on http://localhost:8080/.\nWe will now submit a simple workflow to test if Steep is running correctly. The workflow consists of a single execute action that sleeps for 10 seconds and then quits. Run the following command:\nTerminal\nThe command will return the ID of the submitted workflow. You can monitor the execution in the web interface or by issuing the following command:\nTerminal\nReplace [WORKFLOW ID] with the returned ID.\nCongratulations! You’ve successfully installed Steep and ran your first workflow."},{"slug":"agents","body":"Data models\nAn agent represents an instance of Steep that can execute process chains.\nPropertyTypeDescription\nid\nA unique agent identifier\navailable\ntrue if the agent is currently idle and new process chains can be assigned to it, false if it is busy executing a process chain\ncapabilities\nA set of strings specifying capabilities the agent provides. See also setups.\nstartTime\nAn ISO 8601 timestamp denoting the date and time when the agent has started.\nstateChangedTime\nAn ISO 8601 timestamp denoting the date and time when the value of the available property changed from true to false (i.e. when the agent became busy) or from false to true (when it became available)\nprocessChainId\nThe ID of the process chain currently allocated to this agent. May be null if no process chain has been allocated to the agent (i.e. if it is currently available).\n"},{"slug":"get-information","body":"Get information about Steep. This includes:\n * Steep’s version number\n * A build ID\n * A SHA of the Git commit for which the build was created\n * A timestamp of the moment when the build was created\nResource URL\nParameters\nNone\nStatus codes\n200\nThe operation was successful\nExample request\nExample response\n"},{"slug":"get-health","body":"An endpoint that can be used by external applications at regular intervals to monitor Steep’s health, i.e. to check if it works correctly and if the underlying database as well as all remote agents are reachable.\nThe response is a JSON object, which will always contain the attribute health. This attribute can be either true if Steep works correctly or false if some error has occurred. Apart from that, the response may contain additional information about data stored in the database (such as the number of submissions) as well as information about remote agents. However, these attributes are not defined and may change in future versions.\nResource URL\nParameters\nNone\nStatus codes\n200\nThe operation was successful\n503\nService unavailable. Steep may not work as expected.\nExample request\nExample response\n"},{"slug":"get-submissions","body":"Get information about all submissions in the database. The response is a JSON array consisting of submission objects without the properties workflow, results, and errorMessage. In order to get the complete details of a submission, use the GET submission by ID endpoint.\nThe submissions are returned in the order in which they were added to the database with the newest ones at the top.\nResource URL\nParameters\nsize\nThe maximum number of submissions to return. The default value is 10.\noffset\nThe offset of the first submission to return. The default value is 0.\nstatus\nIf this parameter is defined, Steep will only return submissions with the given status. Otherwise, it will return all submissions from the database. See the list of submission statuses for valid values.\nResponse headers\nx-page-size\nThe size of the current page (i.e. the maximum number of submission objects returned). See size request parameter.\nx-page-offset\nThe offset of the first submission returned. See offset request parameter\nx-page-total\nThe total number of submissions in the database matching the given request parameters.\nStatus codes\n200\nThe operation was successful\n400\nOne of the parameters was invalid. See response body for error message.\nExample request\nExample response\n"},{"slug":"get-submission-by-id","body":"Get details about a single submission from the database.\nResource URL\nParameters\nid\nThe ID of the submission to return\nStatus codes\n200\nThe operation was successful\n404\nThe submssion was not found\nExample request\nExample response\n"},{"slug":"put-submission","body":"Update a submission. The request body is a JSON object with the submission properties to update. At the moment, only the status and priority properties can be updated.\nIf the operation was successful, the response body contains the updated submission without the properties workflow, results, and errorMessage.\nNotes:\n * You can use this endpoint to cancel the execution of a submission (see example below).\n * If you update a submission’s priority, the priorities of all process chains that belong to this submission and have a status of either REGISTERED, RUNNING, or PAUSED will be updated too. Also, all process chains generated from this submission in the future will receive the updated priority. Finished process chains will not be modified.\nResource URL\nParameters\nid\nThe ID of the submission to update\nStatus codes\n200\nThe operation was successful\n400\nThe request body was invalid\n404\nThe submission was not found\nExample request\nExample response\n"},{"slug":"post-workflow","body":"Create a new submission. The request body contains the workflow to execute.\nIf the operation was successful, the response body contains submission.\nResource URL\nStatus codes\n202\nThe workflow has been accepted (i.e. stored in the database) and is scheduled for execution.\n400\nThe posted workflow was invalid. See response body for more information.\nExample request\nExample response\n"},{"slug":"get-process-chains","body":"Get information about all process chains in the database. The response is a JSON array consisting of process chain objects without the properties executables, results, totalRuns, runNumber, and autoResumeAfter. In order to get the complete details of a process chain, use the GET process chain by ID endpoint.\nThe process chains are returned in the order in which they were added to the database with the newest ones at the top.\nSome properties such as startTime, status, or endTime depend on a specific process chain run (see the section on process chains for more information about runs). This endpoint always displays the latest run (if available). You can get more information through the endpoints /processchains/:id/runs and /processchains/:id/runs/:runNumber.\nResource URL\nParameters\nsize\nThe maximum number of process chains to return. The default value is 10.\noffset\nThe offset of the first process chain to return. The default value is 0.\nsubmissionId\nIf this parameter is defined, Steep will only return process chains from the submission with the given ID. Otherwise, it will return process chains from all submissions. If there is no submission with the given ID, the result will be an empty array.\nstatus\nIf this parameter is defined, Steep will only return process chains with the given status. Otherwise, it will return all process chains from the database. See the list of process chain statuses for valid values.\nResponse headers\nx-page-size\nThe size of the current page (i.e. the maximum number of process chain objects returned). See size request parameter.\nx-page-offset\nThe offset of the first process chain returned. See offset request parameter\nx-page-total\nThe total number of process chains in the database matching the given request parameters.\nStatus codes\n200\nThe operation was successful\n400\nOne of the parameters was invalid. See response body for error message.\nExample request\nExample response\n"},{"slug":"get-process-chain-by-id","body":"Get details about a single process chain from the database.\nSome properties such as startTime, status, or endTime depend on a specific process chain run (see the section on process chains for more information about runs). This endpoint always displays the latest run (if available). You can get more information through the endpoints /processchains/:id/runs and /processchains/:id/runs/:runNumber.\nResource URL\nParameters\nid\nThe ID of the process chain to return\nStatus codes\n200\nThe operation was successful\n404\nThe process chain was not found\nExample request\nExample response\n"},{"slug":"get-process-chain-logs","body":"Get contents of the log file of a process chain.\nThis endpoint will only return something if process chain logging is enabled in the log configuration. Otherwise, the endpoint will always return HTTP status code 404.\nAlso note that process chain logs are stored on the machine where the Steep agent that has executed the process chain is running. The log files will only be available as long as the machine exists and the agent is still available. If you want to persist log files, define a location on a shared file system in the log configuration.\nThis endpoint supports HTTP range requests, which allows you to only fetch a portion of a process chain’s log file.\nResource URL\nParameters\nid\nThe ID of the process chain whose log file to return\nforceDownload\ntrue if the Content-Disposition header should be set in the response. This is useful if you link to a log file from a web page and want the browser to download the file instead of displaying its contents. The default value is false.\nrunNumber\nSpecifies the actual run of the process chain whose log file to return (see the section on process chains for details on runs). If no run number is given, the endpoint will return the log file of the latest run. Note that a process chain that currently has the status PAUSED or REGISTERED, does not have a latest run. In this case, the endpoint will return HTTP status code 404.\nRequest headers\nRange\nThe part of the log file that should be returned (see HTTP Range header)\nResponse headers\nAccept-Ranges\nA marker to advertise support of range requests (see HTTP Accept-Ranges header)\nContent-Range\nIndicates what part of the log file is delivered (see HTTP Content-Range header)\nStatus codes\n200\nThe operation was successful\n206\nPartial content will be delivered in response to a range request\n400\nThe given run number is invalid (either not a number or less than 1)\n404\na) Process chain log file could not be found. Possible reasons: (1) the process chain has not produced any output (yet), (2) the agent that has executed the process chain is not available anymore, (3) process chain logging is disabled in Steep’s configuration, (4) the process chain has the status PAUSED or REGISTERED, (5) the given run number was out of range\n416\nRange not satisfiable\nExample request\nExample response\n"},{"slug":"get-process-chain-runs","body":"Return an array of all runs of a process chain.\nA run is represented by an object containing a subset of the properties of a process chain, namely agentId, startTime, endTime, status, errorMessage, and autoResumeAfter. See the section on process chains for more information about runs and these properties.\nRuns are ordered by their run number from 1 to n where n is the total number of runs (see process chain property totalRuns).\nResource URL\nParameters\nid\nThe ID of the process chain whose runs should be returned\nStatus codes\n200\nThe operation was successful\n404\nThe process chain was not found\nExample request\nExample response\n"},{"slug":"get-process-chain-run-by-run-number","body":"Fetches information about a run of a process chain.\nThe path parameter runNumber specifies the number of the run to return. Run numbers start at 1 in continuously increasing order. The process chain property totalRuns specifies how many runs the process chain has.\nThis endpoint renders a view of a process chain for the run with the given runNumber. It renders objects similar to the ones returned by the /processchains/:id endpoint. If runNumber equals totalRuns, both endpoints return the exact same object (because /processchains/:id always renders the latest run).\nResource URL\nParameters\nid\nThe ID of the process chain whose runs should be returned\nrunNumber\nThe number of the run to render\nStatus codes\n200\nThe operation was successful\n400\nThe run number was invalid (i.e. not a number)\n404\nEither the process chain or the run were not found\nExample request\nExample response\nSee /processchains/:id endpoint."},{"slug":"head-process-chain-logs","body":"This endpoint can be used to check if a process chain log file exists and how large it is. For more information, please refer to the GET process chain logs endpoint.\nResource URL\nParameters\nid\nThe ID of the process chain whose log file to check\nResponse headers\nContent-Length\nThe total size of the log file\nAccept-Ranges\nA marker to advertise support of range requests (see HTTP Accept-Ranges header)\nStatus codes\n200\nThe operation was successful\n404\nProcess chain log file could not be found. Possible reasons: (1) the process chain has not produced any output (yet), (2) the agent that has executed the process chain is not available anymore, (3) process chain logging is disabled in Steep’s configuration\nExample request\nExample response\n"},{"slug":"put-process-chain","body":"Update a process chain. The request body is a JSON object with the process chain properties to update. At the moment, only the status and priority properties can be updated.\nIf the operation was successful, the response body contains the updated process chain without the properties executables and results.\nNotes:\n * You can use this endpoint to cancel the execution of a process chain (see example below).\n * The priority can only be modified if the process chain status is REGISTERED, RUNNING, or PAUSED. Otherwise, the operation will result in HTTP error 422.\nResource URL\nParameters\nid\nThe ID of the process chain to update\nStatus codes\n200\nThe operation was successful\n400\nThe request body was invalid\n404\nThe process chain was not found\n422\nThe process chain’s priority could not be modified because the process chain is already finished, i.e. the process chain status is not REGISTERED, RUNNING, or PAUSED\nExample request\nExample response\n"},{"slug":"get-agents","body":"Get information about all agents currently connected to the cluster. In order to get details about a single agent, use the GET agent by ID endpoint.\nResource URL\nParameters\nNone\nStatus codes\n200\nThe operation was successful\nExample request\nExample response\n"},{"slug":"get-agent-by-id","body":"Get details about a single agent.\nResource URL\nParameters\nid\nThe ID of the agent to return\nStatus codes\n200\nThe operation was successful\n404\nThe agent was not found\nExample request\nExample response\n"},{"slug":"get-vms","body":"Get information about all VMs in the database. To get details about a single VM, use the GET VM by ID endpoint.\nThe VMs are returned in the order in which they were added to the database with the newest ones at the top.\nResource URL\nParameters\nsize\nThe maximum number of VMs to return. The default value is 10.\noffset\nThe offset of the first VM to return. The default value is 0.\nstatus\nIf this parameter is defined, Steep will only return VMs with the given status. Otherwise, it will return all VMs from the database. See the list of VM statuses for valid values.\nResponse headers\nx-page-size\nThe size of the current page (i.e. the maximum number of VM objects returned). See size request parameter.\nx-page-offset\nThe offset of the first VM returned. See offset request parameter\nx-page-total\nThe total number of VMs in the database matching the given request parameters.\nStatus codes\n200\nThe operation was successful\n400\nOne of the parameters was invalid. See response body for error message.\nExample request\nExample response\n"},{"slug":"get-vm-by-id","body":"Get details about a single VM from the database.\nResource URL\nParameters\nid\nThe ID of the VM to return\nStatus codes\n200\nThe operation was successful\n404\nThe VM was not found\nExample request\nExample response\n"},{"slug":"get-plugins","body":"Get information about all configured plugins. To get information about a single plugin, use the GET plugin by name endpoint.\nResource URL\nParameters\nNone\nStatus codes\n200\nThe operation was successful\nExample request\nExample response\n"},{"slug":"get-plugin-by-name","body":"Get information about a single plugin.\nResource URL\nParameters\nname\nThe name of the plugin to return\nStatus codes\n200\nThe operation was successful\n404\nThe plugin was not found\nExample request\nExample response\n"},{"slug":"get-services","body":"Get information about all configured service metadata. To get metadata of a single service, use the GET service by ID endpoint.\nResource URL\nParameters\nNone\nStatus codes\n200\nThe operation was successful\nExample request\nExample response\n"},{"slug":"get-service-by-id","body":"Get configured metadata of a single service.\nResource URL\nParameters\nid\nThe ID of the service to return\nStatus codes\n200\nThe operation was successful\n404\nThe service metadata was not found\nExample request\nExample response\n"},{"slug":"get-setups","body":"Get information about all configured setups. To get a single setup, use the GET setup by ID endpoint.\nResource URL\nParameters\nNone\nStatus codes\n200\nThe operation was successful\n404\nSetups are unavailable because cloud configuration is disabled\nExample request\nExample response\n"},{"slug":"get-setup-by-id","body":"Get information about a single setup.\nResource URL\nParameters\nid\nThe ID of the setup to return\nStatus codes\n200\nThe operation was successful\n404\nThe setup cannot be found or setups are unavailable because cloud configuration is disabled\nExample request\nExample response\n"},{"slug":"get-search","body":"Perform a full-text search in Steep’s database to find submissions and process chains.\nThe response is a JSON object with the attributes counts and results:\n * counts is an object containing the total number of matches in the database for each possible object type (workflow and processChain) as well as a total sum (total). The numbers may either be exact or estimated depending on the count parameter given in the request. The object might also be left off if count equals none.\n * results is a list of search result objects sorted by relevance.\nResource URL\nParameters\nq\nThe search query\nsize\nThe maximum number of search results to return. The default value is 10.\noffset\nThe offset of the first search result to return. The default value is 0.\ncount\nSpecifies how Steep should count the total number of search results and if they should be included in the response. Possible values are: exact to include an exact count in the response (may take a long time depending on how many objects match), estimate to include a rough estimate (very fast but might be incorrect), and none if the total number of results should not be counted at all. The default value is estimate.\ntimeZone\nAn ID of the time zone in which dates and times in the query are specified (typically the time zone of the client or web browser). Valid values are taken from the IANA Time Zone database (e.g. Europe/Berlin). Defaults to the server’s time zone.\nStatus codes\n200\nThe operation was successful\n400\nOne of the parameters was invalid. See response body for error message.\nExample request\nExample response\n"},{"slug":"get-prometheus-metrics","body":"Steep can provide metrics to Prometheus. Besides statistics about the Java Virtual Machine that Steep is running in, the following metrics are included:\nMetricDescription\nsteep_remote_agents\nThe number of registered remote agents\nsteep_controller_process_chains\nThe number of generated process chains the controller is currently waiting for grouped by submissionId\nsteep_scheduler_process_chains\nThe number of process chains with a given status (indicated by the label status)\nsteep_local_agent_retries\nThe total number of times an executable with a given service ID (indicated by the label serviceId) had to be retried\nsteep_eventbus_compressedjson_messages\nTotal number of compressed JSON messages sent/received over the event bus (label operation is either sent or recv)\nsteep_eventbus_compressedjson_bytes\nTotal number of compressed JSON bytes. Label operation is either sent or recv, and label stage is either compressed or uncompressed. Uncompressed bytes will be compressed before they are sent over the event bus, and received compressed bytes will be uncompressed.\nsteep_eventbus_compressedjson_time\nTotal number of milliseconds spent compressing or decompressing JSON (label operation is either sent or recv and specifies if sent bytes have been compressed or received bytes have been uncompressed)\nResource URL\nParameters\nNone\nStatus codes\n200\nThe operation was successful\nExample request\nExample response\n"},{"slug":"http-endpoints","body":"Interfaces\nThe main way to communicate with Steep (i.e. to submit workflows, to monitor progress, fetch metadata, etc.) is through its HTTP interface. By default, Steep listens to incoming connections on port 8080."},{"slug":"running-two-services-in-parallel","body":"This example workflow consists of two execute actions that each copy a file. Since both actions do not depend on each other (i.e. they do not share any variable), Steep converts them to two independent process chains and executes them in parallel (as long as there are at least two agents available).\nThe two execute actions refer to the copy service. The service metadata of copy defines that this processing service has an input parameter input_file and an output parameter output_file, both of which must be specified exactly one time (cardinality equals 1..1).\nThe input parameters are given (example1.txt and example2.txt). The output parameters refer to the variables outputFile1 and outputFile2 and have no value. Steep will create unique values (output file names) for them during workflow execution.\nWorkflow\nconf/steep.yaml\n"},{"slug":"chaining-two-services","body":"The following example workflow makes a copy of a file and then a copy of the copy (i.e. the file is copied and the result is copied again). The workflow contains two actions that share the same variable: outputFile1 is used as the output of the first action and as the input of the second action. Steep executes them in sequence.\nThe service metadata for this workflow is the same as for the previous one.\nWorkflow\n"},{"slug":"splitting-and-joining-results","body":"This example starts with an action that copies a file. Two other actions then run in parallel and make copies of the result of the first action. A final action then joins these copies to a single file. The workflow has a split-and-join pattern because the graph is split into two branches after the first action. These branches are then joined into a single one with the final action.\nWorkflow\nconf/services.yaml\n"},{"slug":"processing-a-dynamic-number-of-results-in-parallel","body":"This example demonstrates how to process the results of an action in parallel even if the number of result files is unknown during design of the workflow. The workflow starts with an action that splits an input file example.txt into multiple files (e.g. one file per line) stored in a directory outputDirectory. A for-each action then iterates over these files and creates copies. The for-each action has an iterator i that serves as the input for the individual instances of the copy service. The output files (outputFile1) of this service are collected via the yieldToOutput property in a variable called copies. The final join service merges these copies into a single file outputFile2.\nWorkflow\nconf/services.yaml\n"},{"slug":"feeding-results-back-into-the-workflow-cyclesloops","body":"The following example shows how to create loops with a dynamic number of iterations. Suppose there is a processing service called countdown.js that reads a number from an input file, decreases this number by 1, and then writes the result to an output file. The service could be implemented in Node.js as follows:\ncountdown.js\nThe following workflow uses this service in a for-each action to continuously reprocess a file and decrease the number in it until it reaches 0.\nIn the first iteration of the for-each action, the service reads from a file called input.txt and writes to an output file with a name generated during runtime. The path of this output file is routed back into the for-each action via yieldToInput. In the second iteration, the service reads from the output file and produces another one. This process continues until the number equals 0. In this case, the service does not write an output file anymore and the workflow finishes.\nNote that we use the data type fileOrEmptyList in the service metadata for the output parameter of the countdown service. This is a special data type that either returns the generated file or an empty list if the file does not exist. In the latter case, the for-each action does not have any more input values to process. Think of the input of a for-each action as a queue. If nothing is pushed into the queue and all elements have already been processed, the for-each action can finish.\nWorkflow\nconf/services.yaml\n"},{"slug":"example-workflows","body":"Introduction\nThis page introduces example workflows covering patterns regularly seen in real-world use cases. The required service metadata for each workflow is also provided."},{"slug":"workflow-scheduling","body":"In literature, a workflow is typically represented by a directed graph that describes how an input data set is processed by certain tasks in a given order to produce a desired outcome. The following figure shows a simple example in the extended Petri Net notation proposed by van der Aalst and van Hee (2004).\nABDEC\nThe workflow starts with an input file that is read by a task A. This task produces two results. The first one is processed by task B whose result is in turn sent to C. The second result of A is processed by D. The outcomes of C and D are finally processed by task E. This is a very simple example. In practice, workflows can become very large with hundreds up to several thousands of tasks processing large numbers of input files.\nIn order to be able to schedule such a workflow in a distributed environment, the graph has to be transformed to individual executable units. Steep follows a hybrid scheduling approach that applies heuristics on the level of the workflow graph and later on the level of individual executable units. It assumes that tasks that access the same data should be executed on the same machine to reduce the communication overhead and to improve file reuse. Steep therefore groups tasks into so-called process chains, which are linear sequential lists (without branches and loops).\nTransforming workflows into process chains is an iterative process. In each iteration, Steep finds the longest linear sequences of tasks and groups them to process chains. The following animation shows how this works for our example workflow:\nABDEC\nTask A will be put into a process chain in iteration 1. Steep then schedules the execution of this process chain. After the execution has finished, Steep uses the results to produce a process chain containing B and C and another one containing D. These process chains are then scheduled to be executed in parallel. The results are finally used to generate the fourth process chain containing task E, which is also scheduled for execution."},{"slug":"software-architecture","body":"The following figure shows the main components of Steep: the HTTP server, the controller, the scheduler, the agent, and the cloud manager.\nTogether, these components form an instance of Steep. In practice, each instance typically runs on a separate virtual machine, but multiple instances can also be started on the same machine. Each component can be enabled or disabled in a given instance (see configuration options for more information). This means, in a cluster, there can be instances that have all five components enabled, and others that only have an agent, for example.\nAll components of all instances communicate with each other through messages sent over an event bus. Further, the HTTP server, the controller, and the scheduler are able to connect to a shared database.\nThe HTTP server provides information about scheduled, running, and finished workflows to clients. Clients can also upload a new workflow. In such a case, the HTTP server puts the workflow into the database and sends a message to one of the instances of the controller.\nThe controller receives this message, loads the workflow from the database, and starts transforming it iteratively to process chains as described above. Whenever it has generated new process chains, it puts them into the database and sends a message to all instances of the scheduler.\nThe schedulers then select agents to execute the process chains. They load the process chains from the database, send them via the event bus to the selected agents for execution, and finally write the results into the database. The schedulers also send a message back to the controller so it can continue with the next iteration and generate more process chains until the workflow has been completely transformed.\nIn case a scheduler does not find an agent suitable for the execution of a process chain, it sends a message to the cloud manager (a component that interacts with the API of the Cloud infrastructure) and asks it to create a new agent."},{"slug":"processing-services","body":"Steep is very flexible and allows a wide range of processing services (or microservices) to be integrated. A typical processing service is a program that reads one or more input files and writes one or more output files. The program may also accept generic parameters. The service can be implemented in any programming language (as long as the binary or script is executable on the machine on which the Steep agent is running) or can be wrapped in a Docker container.\nFor a seamless integration, a processing service should adhere to the following guidelines:\n * Every processing service should be a microservice. It should run in its own process and serve one specific purpose.\n * As Steep needs to call the service in a distributed environment, it should not have a graphical user interface or require any human interaction during the runtime. Suitable services are command-line applications that accept arguments to specify input files, output files, and parameters.\n * The service should read from input files, process the data, write results to output files, and then exit. It should not run continuously like a web service. If you need to integrate a web service in your workflow, we recommend using the curl command or something similar.\n * Steep does not require the processing services to implement a specific interface. Instead, the service’s input and output parameters should be described in a special data model called service metadata.\n * According to common conventions for exit codes, a processing service should return 0 (zero) upon successful execution and any number but zero in case an error has occurred (e.g. 1, 2, 128, 255, etc.).\n * In order to ensure deterministic workflow executions, services should be stateless and idempotent. This means that every execution of a service with the same input data and the same set of parameters should produce the same result."},{"slug":"how-does-steep-work","body":"Introduction\nTo answer this question, we will first describe how Steep transforms workflow graphs into executable units. After that, we will have a look at Steep’s software architecture and what kind of processing services it can execute.\nThis guide is based on the following publication: Krämer, M. (2020). Capability-Based Scheduling of Scientific Workflows in the Cloud. Proceedings of the 9th International Conference on Data Science, Technology, and Applications DATA, 43–54. https://doi.org/10.5220/0009805400430054"},{"slug":"custom-runtime-environments","body":"Extending Steep through plugins\nA runtime plugin is a function that can run process chain executables inside a certain runtime environment. See the runtime property of service metadata.\nThe plugin’s function takes an executable to run and an output collector. The output collector is a simple interface, to which the executable’s standard output should be forwarded. If required, the function can be a suspend function.\nUse this plugin if you want to implement a special way to execute processing services. For example, you can implement a remote web service call, or you can use one of the existing runtimes and run a certain service in a special way (like in the example plugin below).\nType\nruntime\nAdditional propertiesType\nsupportedRuntime\nThe name of the runtime this plugin provides. Use this value in your service metadata.\nFunction interface\nExample descriptor (Source)\nExample plugin script (Source)\n"},{"slug":"output-adapters","body":"Extending Steep through plugins\nAn output adapter plugin is a function that can manipulate the output of services depending on their produced data type (see the dataType property of the service parameter data model, as well as the dataType property of the process chain argument data model).\nIn other words, if an output parameter of a processing service has a specific dataType defined in the service’s metadata and this data type matches the one given in the output adapter’s descriptor, then the plugin’s function will be called after the service has been executed. Steep will pass the output argument and the whole process chain (for reference) to the plugin. The output argument’s value will be the current result (i.e. the output file or directory). The plugin can modify this file or directory (if necessary) and return a new list of files that will then be used by Steep for further processing.\nSteep has a built-in output adapter for the data type directory. Whenever you specify this data type in the service metadata, Steep will pass the output directory to an internal function that recursively collects all files from this directory and returns them as a list.\nThe example output adapter fileOrEmptyList described below is also included in Steep. It checks if an output file exists (i.e. if the processing service has actually created it) and either returns a list with a single element (the file) or an empty list. This is useful if a processing service has an optional output that you want to use as input of a subsequent for-each action or of the current for-each action via yieldToInput.\nIf required, the function can be a suspend function.\nType\noutputAdapter\nAdditional propertiesType\nsupportedDataType\nThe dataType that this plugin can handle\nFunction interface\nExample descriptor\nExample plugin script\n"},{"slug":"initializers","body":"Extending Steep through plugins\nAn initializer plugin is a function that will be called during the initialization phase of Steep just before components such as the controller or the scheduler are deployed. If required, the function can be a suspend function.\nType\ninitializer\nAdditional propertiesType\ndependsOn\nAn optional list of names of other initializer plugins that need to be executed before this plugin. If this property is not given, the order in which initializer plugins are executed is undefined.\nFunction interface\nExample descriptor\nExample plugin script\n"},{"slug":"query-language","body":"The focus of Steep’s query language is on end users. It is lightweight and contains only a few operators. There are no logical combinators such as AND or OR. The main idea is that Steep tries to find as many objects matching the query as possible and then sorts them by relevance, so the best matches are on the top of the list. It is assumed that workflows have a higher relevance than process chains. If you are using the search through the web interface, you will typically find what you are looking for on one of the first pages. You rarely have to access any page after the second or third one. This is similar to how a web search engine works.\nA search query consists of one or more of the following elements:\nTerm\nA string that should appear somewhere in the document to find.\nPut one or more terms into quotation marks (single or double) if you want to look for exact matches (including spaces). Within quoted terms, quotation marks can be escaped with the backslash character \\.\nEXAMPLES:\ndocker\n\"exact match\"\n\"an \\\"exact match\\\" with quotation marks\"\nDate\nA string in the form yyyy-MM-dd\nThe operators < (less than), <= (less than or equal to), > (greater than), and >= (greater than or equal to) can be used to find objects with a date that is before or after the given one.\nEXAMPLES:\n2023-08-11\n<2023-08-11\n>=2023-08-11\nDate/time\nA string in the form yyyy-MM-dd'T'HH:mm[:ss]. Seconds are optional.\nThe operators < (less than), <= (less than or equal to), > (greater than), and >= (greater than or equal to) can be used to find objects with a date/time pair that is before or after the given one.\nEXAMPLES:\n2023-08-11T21:56\n2023-08-11T21:56:07\n>2023-08-11T21:56\n<=2023-08-11T21:56:07\nTime range\nA string representing a time range in the form yyyy-MM-dd['T'HH:mm[:ss]]..yyyy-MM-dd['T'HH:mm[:ss]]. Times as well as seconds within times are optional. The time range is inclusive, which means that objects with a date that matches the given start date as well as those with a date matching the given end date are included.\nEXAMPLES:\n2023-08-10..2023-08-11\n2023-08-11T21:55..2023-08-11T21:56\nLocator\nA string starting with in: and denoting the attribute that should be compared with the give term(s), dates, date/time pairs, and time ranges. See Attributes below for a complete list of all possible attributes.\nExample: in:name\nType\nA string starting with is: and denoting the type of documents to search. Possible values are is:workflow and is:processchain.\nFilter\nA string that consists of an attribute name, followed by a colon and a term, date, date/time pair, or time range that should appear in this attribute. See Attributes below for a complete list of all possible attributes.\nEXAMPLES:\nname:Elvis\nstart:<=2023-08-11\nAttributes\nPossible values (including aliases) for attributes are:\n * id\n * name\n * error, errormessage\n * rc, cap, reqcap, capability, requiredcapability, rcs, caps, reqcaps, capabilities, requiredcapabilities\n * source\n * start, startTime\n * end, endTime\nSee the submission and process chain data models for more information about these attributes."},{"slug":"search-examples","body":"filename highmemory\nSearch for objects that contain the terms filename or highmemory in any of their attributes. Since results are sorted by relevance, objects matching both terms will appear at the top of the list.\n\"exact match\"\nUse quotation marks to search for literal (exact) strings.\nfilename is:workflow\nSearch for the term filename but only in workflows.\nerror:127 is:processchain\nSearch for process chains whose error message contains the term 127.\nhighmemory in:requiredcapabilities\nSearch for objects where the term highmemory appears in the list of required capabilities. Does not include objects where the term highmemory appears in any other attribute but the required capabilities.\nrcs:highmemory\nSearch for objects whose required capabilities (alias rcs) contain the term highmemory.\nfilename status:error\nSearch for objects containing the term filename but only if their status equals error.\n2023-08-11\nSearch for workflows or process chains that have started or finished on 11 August 2023.\n<2023-08-11T21:56\nSearch for workflows or process chains that have started or finished before 21:56 on 11 August 2023.\n>=2023-08-11T21:56:07\nSearch for workflows or process chains that have started or finished at or after 21:56:07 on 11 August 2023.\nstart:2023-08-10..2023-08-11\nSearch for workflows or process chains that have been started between 10 August 2023 and 11 August 2023 (inclusive).\nfilename in:source is:workflow rcs:highmemory\nSearch for workflows containing the term filename in their source and whose required capabilities contain the term highmemory.\nexit code 127 in:error is:processchain\nSearch for process chains containing the terms exit, code, or 127 in their error message. Objects containing all terms in their error message will get a higher relevance and appear at the top of the list."},{"slug":"search-results","body":"The HTTP endpoint /search returns a list of search result objects. Each such object refers to an item found and contains information about which properties of this item have matched with which search term and where in these properties the search term has been found.\nThe following list describes the properties of this object. For more information about each individual property, please refer to the description of the submission and process chain data models.\nPropertyTypeDescription\nid\nThe ID of the found item\ntype\nThe item’s type. Possible values are workflow and processChain.\nrequiredCapabilities\nThe capabilities required for this item to be executed.\nstatus\nThe current status of the item\nname\nAn optional human-readable name (only included if type is workflow and if the workflow has a name)\nstartTime\nAn ISO 8601 timestamp denoting the date and time when the item was started. May be null if the execution has not started yet.\nendTime\nAn ISO 8601 timestamp denoting the date and time when the execution of the item has finished. May be null if the execution has not finished yet.\nmatches\nA list of match objects denoting which properties have matched and what term was found at which location.\n"},{"slug":"matches","body":"A match object specifies a which property of an item has matched with which search term and where the match has occurred.\nPropertyTypeDescription\nlocator\nThe property in which the match was found. Possible values are errorMessage, id, name, requiredCapabilities, source, status, startTime, endTime. See the description of the submission and process chain data models for more information about these properties.\nfragment\nA fragment of the property’s value (an ‘excerpt’ or a ‘preview’). If the property’s value is small enough, the fragment might even contain the whole value.\ntermMatches\nA list of matches within fragment (see below)\ntermMatches is an array of objects with the following properties:\nPropertyTypeDescription\nterm\nThe matched term from the search query\nindices\nThe start positions (relative to fragment) at which the term was found\n"},{"slug":"full-text-search","body":"Data models\nSteep contains a powerful full-text search engine that be used to find submissions and process chains in the backend database. The search engine can be accessed through the /search HTTP endpoint or through the web-based user interface."},{"slug":"process-chain-adapters","body":"Extending Steep through plugins\nA process chain adapter plugin is a function that can manipulate generated process chains before they are executed.\nIt takes a list of generated process chains and a reference to the workflow from which the process chains have been generated. It returns a new list of process chains to execute or the given list if no modification was made. If required, the function can be a suspend function.\nType\nprocessChainAdapter\nAdditional propertiesType\ndependsOn\nAn optional list of names of other process chain adapter plugins that need to be executed before this plugin. If this property is not given, the order in which process chain adapter plugins are applied to process chains is undefined.\nFunction interface\nExample descriptor\nExample plugin script\n"},{"slug":"parameter-injection","body":"For compatibility reasons, the plugin function signatures are not fixed. Whenever a plugin function is called, its arguments are injected based on their type. For example, if the function requires an instance of io.vertx.core.Vertx, such an object will be passed. This is independent of where this argument appears in the parameter list. In the function signatures described above, the Vert.x instance is always the last parameter, but actually, it could be at any position and the injection mechanism would still work.\nThis feature allows us as Steep developers to add new parameters in the future to the function signatures without requiring all users to change their plugins. It also allows plugin developers to specify parameters in any order and to even leave out parameters if they are not needed. For example, a process chain adapter could also have the following signature:\nNote that a parameter can only be injected into a plugin of a certain type, if it is described in the function signature of this plugin type above. For example, the function signature of a runtime plugin does not specify a workflow, so a workflow cannot be injected. Trying to define a runtime plugin with such a parameter will result in an error."},{"slug":"plugin-overview","body":"Extending Steep through plugins\nSteep can be extended through plugins. Each plugin is a Kotlin script with the file extension .kt or .kts. Inside this script, there should be a single function with the same name as the plugin and a signature that depends on the plugin type. Function interfaces are described in the sub-sections below.\nAll plugins must be referenced in the plugins/common.yaml file. This file is an array of descriptor objects with at least the following properties:\nPropertyTypeDescription\nname\nA unique name of the plugin (the function inside the plugin’s script file must have the same name)\ntype\nThe plugin type. Valid values are: initializer, outputAdapter, processChainAdapter, processChainConsistencyChecker, and runtime.\nscriptFile\nThe path to the plugin’s Kotlin script file. The file should have the extension .kt or .kts. The path is relative to Steep’s application directory, so a valid example is conf/plugins/fileOrEmptyList.kt.\nversion\nThe plugin’s version. Must follow the Semantic Versioning Specification.\nSpecific plugin types may require additional properties described in the sub-sections below.\nPlugins are compiled on demand when Steep is starting. This can take some time depending on the number of the plugins and their size. For faster start times, you can configure a persistent compiled plugin cache. Steep updates this cache on startup when it has first compiled a script or when it detects that a previously compiled script has changed. On subsequent startups, Steep can utilize the cache to skip compilation of known plugins and, therefore, to reduce startup time."},{"slug":"pluginscommonyaml","body":"Configuration\nThe configuration file plugins/common.yaml describes all plugins so Steep can compile and use them during runtime. The file contains an array of descriptor objects with the properties specified in the section on extending Steep through plugins.\nNote: The path to the plugin configuration file can be configured with the item steep.plugins in Steep’s general configuration.\nplugins/common.yaml\n"},{"slug":"executables","body":"An executable is part of a process chain. It describes how a processing service should be executed and with which parameters.\nPropertyTypeDescription\nid\nAn identifier (does not have to be unique). Typically refers to the id of the execute action, from which the executable was derived. Possibly suffixed with a dollar sign $ and a number denoting the iteration of an enclosing for-each action (e.g. myaction$1) or nested for-each actions (e.g. myaction$2$1).\npath\nThe path to the binary of the service to be executed. This property is specific to the runtime. For example, for the docker runtime, this property refers to the Docker image.\nserviceId\nThe ID of the processing service to be executed.\narguments\nA list of arguments to pass to the service. May be empty.\nruntime\nThe name of the runtime that will execute the service. Built-in runtimes are currently other (for any service that is executable on the target system) and docker for Docker containers. More runtimes can be added through plugins\nruntimeArgs\nA list of arguments to pass to the runtime. May be empty.\nretries\nAn optional retry policy specifying how often this executable should be restarted in case of an error.\nmaxInactivity\nAn optional timeout policy that defines how long the executable can run without producing any output (i.e. without writing anything to the standard output and error streams) before it is automatically cancelled or aborted.\nmaxRuntime\nAn optional timeout policy that defines how long the executable can run before it is automatically cancelled or aborted, even if the service regularly writes to the standard output and error streams.\ndeadline\nAn optional timeout policy that defines how long the executable can run at all (including all retries and their associated delays) until it is cancelled or aborted.\nAn argument is part of an executable.\nPropertyTypeDescription\nid\nAn argument identifier\nlabel\nAn optional label to use when the argument is passed to the service (e.g. --input).\nvariable\nA variable that holds the value of this argument.\ntype\nThe type of this argument. Valid values: input, output\ndataType\nThe type of the argument value. If this property is directory, Steep will create a new directory for the service’s output and recursively search it for result files after the service has been executed. Otherwise, this property can be an arbitrary string. New data types with special handling can be added through output adapter plugins.\nAn argument variable holds the value of an argument.\nPropertyTypeDescription\nid\nThe variable’s unique identifier\nvalue\nThe variable’s value\n"},{"slug":"arguments","body":"An argument is part of an executable.\nPropertyTypeDescription\nid\nAn argument identifier\nlabel\nAn optional label to use when the argument is passed to the service (e.g. --input).\nvariable\nA variable that holds the value of this argument.\ntype\nThe type of this argument. Valid values: input, output\ndataType\nThe type of the argument value. If this property is directory, Steep will create a new directory for the service’s output and recursively search it for result files after the service has been executed. Otherwise, this property can be an arbitrary string. New data types with special handling can be added through output adapter plugins.\n"},{"slug":"argument-variables","body":"An argument variable holds the value of an argument.\nPropertyTypeDescription\nid\nThe variable’s unique identifier\nvalue\nThe variable’s value\n"},{"slug":"process-chain-status","body":"The following table shows the statuses a process chain can have:\nStatusDescription\nREGISTERED\nThe process chain has been created but execution has not started yet\nRUNNING\nThe process chain is currently being executed\nPAUSED\nThe execution of the process chain is paused\nCANCELLED\nThe execution of the process chain was cancelled\nSUCCESS\nThe process chain was executed successfully\nERROR\nThe execution of the process chain failed"},{"slug":"process-chains","body":"Data models\nAs described in the section on workflow scheduling, Steep transforms a workflow to one or more process chains. A process chain is a sequential list of instructions that will be sent to Steep’s remote agents to execute processing services in a distributed environment.\nSome of the properties specified in the table below are only available once Steep has started executing a process chain (e.g. startTime) or after the execution has finished (e.g. endTime).\nAlso, the /processchains HTTP endpoint, which provides a list of process chains, omits some properties although they are marked as required in the table below (e.g. executables or totalRuns). If you want to get all required properties, you have to use the /processchains/:id HTTP endpoint.\nSteep records each execution of a process chain in a separate ‘run’. The property totalRuns specifies how often a process chain has been executed (including any currently running execution). If a process chain has just been created and still has the status REGISTERED, totalRuns equals 0, but as soon as the status switches to RUNNING, a new run is created and totalRuns is incremented to 1. If a process chain fails and is later retried, for example, a new run will be created and totalRuns will be 2, etc.\nRequesting a process chain through the HTTP endpoints /processchains or /processchains/:id, always renders the latest run. The properties agentId, startTime, endTime, status, errorMessage, and autoResumeAfter depend on the actual run rendered (e.g. different runs have different start times; or one run might have failed, while a newer one might have succeeded or is still running, so their statuses are different). If you want to list all runs of a process chain or retrieve information about a specific run, use the /processchains/:id/runs or /processchains/:id/runs/:runNumber HTTP endpoints, respectively. The property runNumber from the table below specifies, which run out of totalRuns is rendered.\nPropertyTypeDescription\nid\nUnique process chain identifier\nexecutables\nA list of executable objects that describe what processing services should be called and with which arguments\nsubmissionId\nThe ID of the submission to which this process chain belongs\nagentId\nThe ID of the agent that currently executes the process chain (if its status is RUNNING) or has executed it (if it is finished). May be null if the execution has not started yet.\nstartTime\nAn ISO 8601 timestamp denoting the date and time when the process chain execution was started. May be null if the execution has not started yet.\nendTime\nAn ISO 8601 timestamp denoting the date and time when the process chain execution finished. May be null if the execution has not finished yet.\nstatus\nThe current status of the process chain\nrequiredCapabilities\nA set of strings specifying capabilities a host system must provide to be able to execute this process chain. See also setups.\npriority\nA priority used during scheduling. Process chains with higher priorities will be scheduled before those with lower priorities. Negative values are allowed. The default value is 0.\nretries\nAn optional retry policy specifying how often this process chain will be rescheduled in case an error has occurred.\nresults\nIf status is SUCCESS, this property contains the list of process chain result files grouped by their output variable ID. Otherwise, it is null.\ntotalRuns\nThe number of times the process chain has been executed (including any currently running execution).\nrunNumber\nThe number of the run currently rendered. May be null if the process chain has not been executed yet.\nautoResumeAfter\nIf the process chain’s status is PAUSED, this optional property may specify a point in time (as an ISO 8601 timestamp) after which the process chain will be automatically resumed. It is typically only given, if a retry policy is configured (see retries property): if a process chain run has failed and there are still attempts left, autoResumeAfter specifies when the next attempt will be performed.\nestimatedProgress\nA floating point number between 0.0 (0%) and 1.0 (100%) indicating the current execution progress of this process chain. This property will only be provided if the process chain is currently being executed (i.e. if its status equals RUNNING) and if a progress could actually be estimated. Note that the value is an estimation based on various factors and does not have to represent the real progress. More precise values can be calculated with a progress estimator plugin. Sometimes, progress cannot be estimated at all. In this case, the value will be null.\nerrorMessage\nIf status is ERROR, this property contains a human-readable error message. Otherwise, it is null.\n"},{"slug":"process-chain-consistency-checkers","body":"Extending Steep through plugins\nA process chain consistency checker plugin is a function that checks if an execute action can be added to a process chain or if adding it would lead to inconsistencies that render the process chain inexecutable.\nThe function is called before the execute action is converted to an executable and before it is added to the process chain. It takes a list of executables that have been collected so far during process chain generation, the execute action that is about to be converted, the workflow from which the process chain is being created, and a Vert.x instance.\nIt returns true if the execute action can safely be converted and added to the list of executables to make up a new process chain, or false if adding it would lead to a process chain that could not be executed later.\nSteep will not discard actions that a consistency checker plugin has rejected. Instead, it will try to add them to another process chain later. At this point, the plugin will be called again.\nIf required, the function can be a suspend function.\nType\nprocessChainConsistencyChecker\nAdditional propertiesType\ndependsOn\nAn optional list of names of other process chain consistency checker plugins that need to be executed before this plugin. If this property is not given, the order in which consistency checkers are applied to process chains is undefined.\nFunction interface\nExample descriptor\nExample plugin script\n"},{"slug":"runtime-environments","body":"Steep provides a set of default runtime environments that define how processing services are executed. More environments can be added through runtime environment plugins.\nNameDescription\ndocker\nThe service will be executed through Docker. The service metadata attribute path specifies the Docker image to run. The attribute runtimeArgs specifies parameters that should be forwarded to the docker run command.\nother\nThe service will be executed like a normal executable program (binary or shell script)"},{"slug":"service-parameters","body":"This data model describes the parameters that can be passed to a processing service.\nPropertyTypeDescription\nid\nA unique parameter identifier\nname\nA human-readable name\ndescription\nA human-readable description\ntype\nThe type of this parameter. Valid values: input, output\ncardinality\nA string in the form lower..upper specifying how many times the parameter must appear at least (lower limit) and how many times it can appear at most (upper limit). The character n can be used for the upper limit to specify an arbitrary number. The lower limit must not be greater that the upper limit. Examples cardinalities are listed below.\ndataType\nThe type of the parameter value. Steep treats parameters differently depending on the data type (see description below).\ndefault\nAn optional default value for this parameter that will be used if the lower limit of cardinality is 1 but no parameter value is given in the workflow.\nfileSuffix\nAn optional suffix that should be appended to the generated filename of an output parameter. This property is typically used for file extensions (including the dot), e.g. \".xml\" or \".json\".\nlabel\nAn optional string that will be used as a label for the parameter in the service call. Examples are -i, --input, --resolution, etc.\nEXAMPLE CARDINALITIES:\n * \"0..1\" means the parameter is optional (it can appear 0 times or 1 time)\n * \"1..1\" means the parameter is mandatory (it must appear 1 time)\n * \"1..n\" means it must appear at least once or many times (no upper limit)\nDATA TYPE:\nSteep treats parameters differently depending on the type and dataType:\n * If type is \"output\" and dataType is \"directory\", Steep will create a new directory for the service’s output and recursively search it for result files after the service has been executed.\n * If type is \"input\" and dataType is \"directory\", Steep will find the common parent directory of the files from the parameter’s value and pass it to the service. For example, if the parameter’s value is an array with the elements [\"/tmp/a.txt\", \"/tmp/b.txt\", \"/tmp/subdir/c.txt\"], Steep will pass \"/tmp/\" to the service.\n * If type is \"input\", dataType is not \"directory\", but the parameter’s value is an array, Steep will duplicate the parameter as many times as there are items in the array (given that the cardinality has no upper limit).\n * If type is \"input\", dataType is \"boolean\", and the parameter has a label, Steep will pass the label to the service if the parameter’s value is true and ignore the parameter if the value is false.\n * Otherwise, this property can be an arbitrary string. New data types with special handling can be added through output adapter plugins.\n"},{"slug":"runtime-arguments","body":"Runtime arguments are similar to service parameters, except they are passed to the runtime that executes the service (e.g. Docker) instead of the service itself.\nPropertyTypeDescription\nid\nA unique argument identifier\nname\nA human-readable name\ndescription\nA human-readable description\ndataType\nThe type of the parameter value. Typically \"string\" or \"boolean\". The same rules apply as for service parameters.\nlabel\nAn optional string that will be used as a label for the parameter. Examples are -v, --volume, --entrypoint, etc.\nvalue\nAn optional value for this parameter.\n"},{"slug":"service-metadata","body":"Data models\nService metadata is used to describe the interface of a processing service so it can be executed by Steep.\nPropertyTypeDescription\nid\nA unique service identifier\nname\nA human-readable name\ndescription\nA human-readable description\npath\nRelative path to the service executable in the service artefact (or a Docker image if runtime equals docker)\nruntime\nThe runtime environment\nparameters\nA list of service parameters\nruntimeArgs\nAn optional list of arguments to pass to the runtime\nrequiredCapabilities\nA set of strings specifying capabilities a host system must provide to be able to execute this service. See also setups.\nretries\nAn optional retry policy specifying how often the execution of this service should be retried in case of an error. Can be overridden in an executable action.\nmaxInactivity\nduration or object\nAn optional duration or timeout policy that defines how long the execution of this service can take without producing any output (i.e. without writing anything to the standard output and error streams) before it is automatically cancelled or aborted. Can be overridden in an executable action and can be combined with maxRuntime and deadline (see below). Note that a service cancelled due to inactivity is still subject to any configured retry policy, which means its execution may be retried even if one attempt timed out. If you want to cancel a long-running service immediately even if there is a retry policy configured, use a deadline.\nmaxRuntime\nduration or object\nAn optional duration or timeout policy that defines how long the execution of this service can take before it is automatically cancelled or aborted, even if the service regularly writes to the standard output and error streams. Can be overridden in an executable action and can be combined with maxInactivity (see above) and deadline (see below). Note that a service cancelled due to a too long runtime is still subject to any configured retry policy, which means its execution may be retried even if one attempt timed out. If you want to cancel a long-running service immediately even if there is a retry policy configured, use a deadline.\ndeadline\nduration or object\nAn optional duration or timeout policy that defines how long the execution of this service can take at all (including all retries and their associated delays) until it is cancelled or aborted. Can be overridden in an executable action and can be combined with maxInactivity and maxRuntime (see above).\n"},{"slug":"progress-estimators","body":"Extending Steep through plugins\nA progress estimator plugin is a function that analyses the log output of a running processing service to estimate its current progress. For example, the plugin can look for percentages or number of bytes processed. The returned value contributes to the execution progress of a process chain (see the estimatedProgress property of the process chain data model).\nThe function takes the executable that is currently being run and a list of recently collected output lines. It returns an estimated progress between 0.0 (0%) and 1.0 (100%) or null if the progress could not be determined. The function will be called for each output line collected and the newest line is always at the end of the given list. If required, the function can be a suspend function.\nType\nprogressEstimator\nAdditional propertiesType\nsupportedServiceIds\nAn array of IDs of the services this estimator plugin supports\nFunction interface\nExample descriptor\nExample plugin script\n"},{"slug":"volumes","body":"This data model describes an additional volume that can be attached to a virtual machine specified by a setup.\nPropertyTypeDescription\nsizeGb\nThe volume’s size in gigabytes\ntype\nType the volume’s type. By default, the type will be selected automatically.\navailabilityZone\nThe availability zone in which to create the volume. By default, it will be created in the same availability zone as the VM to which it will be attached.\n"},{"slug":"creation-policies","body":"A creation policy defines rules for creating VMs from a certain setup.\nPropertyTypeDescription\nretries\nAn optional retry policy that specifies how many attempts should be made to create a VM (if creation fails) as well as possible (exponential) delays between those attempts. If this property is null, default values from the steep.yaml file will be used.\nlockAfterRetries\nduration\nWhen the maximum number of attempts to create a VM from a certain setup has been reached, the setup will be locked and no other VM with this setup will be created. This property defines how long it will stay locked.\n"},{"slug":"setups","body":"Data models\nA setup describes how a virtual machine (VM) should be created by Steep’s cloud manager.\nPropertyTypeDescription\nid\nA unique setup identifier\nflavor\nThe flavor of the new VM\nimageName\nThe name of the VM image to deploy\navailabilityZone\nThe availability zone in which to create the VM\nblockDeviceSizeGb\nThe size of the VM’s main block device in gigabytes\nblockDeviceVolumeType\nAn optional type of the VM’s main block device. By default, the type will be selected automatically.\nminVMs\nAn optional minimum number of VMs to create with this setup. The default value is 0.\nmaxVMs\nThe maximum number of VMs to create with this setup\nmaxCreateConcurrent\nThe maximum number of VMs to create and provision concurrently. The default value is 1.\nprovisioningScripts\nAn optional list of paths to provisioning scripts that should be executed on the VM after it has been created\nprovidedCapabilities\nAn optional set of strings specifying capabilities that VMs with this setup will have\nsshUsername\nAn optional username for the SSH connection to the created VM. Overrides the main configuration item steep.cloud.ssh.username if it is defined.\nadditionalVolumes\nAn optional list of volumes that will be attached to the VM\nparameters\nAn optional custom object with user-defined properties. Use this object to pass arbitrary values to provisioning scripts where they can be accessed through the global variable setup.\ncreation\nAn optional creation policy that defines rules for creating VMs from this setup. Default values for this parameter are defined in the main configuration.\n"},{"slug":"servicesservicesyaml","body":"Configuration\nThe file services/services.yaml contains an array of service metadata objects describing the interfaces of all processing services Steep can execute.\nNote: The path to the services configuration file can be configured with the item steep.cloud.setups.file in Steep’s cloud configuration.\nservices/services.yaml\n"},{"slug":"global-variables","body":"Here is a list of the global variables defined in provisioning scripts:\nVariableDescription\nagentId\nThe ID of the agent that is about to be deployed on the provisioned VM\nipAddress\nThe IP address of the provisioned VM\nsetup\nA Setup object that describes the configuration of the provisioned VM\nExample provisioning script\n"},{"slug":"environment-variables","body":"Access any environment variable defined on the system where Steep is running (not the VM to be provisioned) as follows:\nExample provisioning script\n"},{"slug":"configuration-values","body":"Use values from Steep’s main configuration file (steep.yaml) as follows:\nExample provisioning script\n"},{"slug":"read-local-files","body":"Insert the contents of a local file into the provisioning script.\nExample provisioning script\n"},{"slug":"upload-local-files-to-remote","body":"Upload one or more local files to the remote VM.\nsource may contain a glob pattern (e.g. *.sh or **/*.yaml) if you want to upload multiple files or if you want to recursively transfer a whole directory tree. In this case, destination should be a directory and it should exist.\nExample provisioning script\n"},{"slug":"provisioning-scripts","body":"Advanced configuration topics\nAfter Steep’s cloud manager has created a VM, it uploads the provisioning scripts defined in the corresponding setup to the VM and executes them. The scripts can be used to deploy software to the VM and to make sure all required services (including Steep) are running.\nEach provisioning script is a simple executable script file with a valid UNIX shebang at the beginning.\nScript files will be processed by a template engine before they are uploaded. The following sections describe supported template instructions."},{"slug":"general-configuration","body":"steep.tmpPathThe path to a directory where temporary files should be stored during processing. Steep generates names for the outputs of execute actions in a workflow. If the store flag of an output parameter is false (which is the default), the generated filename will be relative to this temporary directory.steep.outPathThe path to a directory where output files should be stored. This path will be used instead of steep.tmpPath to generate a filename for an output parameter if its store flag is true.steep.overrideConfigFileThe path to a file that keeps additional configuration. The values of the overrideConfigFile will be merged into the main configuration file, so it basically overrides the default values. Note that configuration items in this file can still be overridden with environment variables. This configuration item is useful if you don’t want to change the main configuration file (or if you cannot do so) but still want to set different configuration values. Use it if you run Steep in a Docker container and bind mount the overrideConfigFile as a volume.steep.servicesThe path to the configuration files containing service metadata. Either a string pointing to a single file, a glob pattern (e.g. **/*.yaml), or an array of files or glob patterns.steep.pluginsThe path to the configuration file(s) containing plugin descriptors. Either a string pointing to a single file, a glob pattern (e.g. **/*.yaml), or an array of files or glob patterns."},{"slug":"cluster-settings","body":"Use these configuration items to build up a cluster of Steep instances. Under the hood, Steep uses Vert.x and Hazelcast, so these configuration items are very similar to the ones found in these two frameworks. To build up a cluster, you need to configure an event bus connection and a cluster connection. They should use different ports. host typically refers to the machine your instance is running on and publicHost or publicAddress specify the hostname or IP address that your Steep instance will use in your network to advertise itself so that other instances can connect to it.\nFor more information, please read the documentation of Vert.x and Hazelcast.\nsteep.cluster.eventBus.host\nThe IP address (or hostname) to bind the clustered eventbus to\nDefault: Automatically detected local network interface\nsteep.cluster.eventBus.port\nThe port the clustered eventbus should listen on\nDefault: A random port\nsteep.cluster.eventBus.publicHost\nThe IP address (or hostname) the eventbus uses to announce itself within in the cluster\nDefault: Same as steep.cluster.eventBus.host\nsteep.cluster.eventBus.publicPort\nThe port that the eventbus uses to announce itself within in the cluster\nDefault: Same as steep.cluster.eventBus.port\nsteep.cluster.hazelcast.clusterName\nAn optional cluster name that can be used to separate clusters of Steep instances. Two instances from different clusters (with different names) cannot connect to each other.\nBy default, no cluster name is set, which means all instances can connect to each other. However, a Steep instance without a cluster name cannot connect to a named cluster.\nHeads up: if you have a cluster name set and you’re using a cloud connection to deploy remote agents on demand, make sure these Steep instances use the same cluster name. Otherwise, you won’t be able to connect to them.\nsteep.cluster.hazelcast.publicAddress\nThe IP address (or hostname) and port Hazelcast uses to announce itself within in the cluster\nsteep.cluster.hazelcast.port\nThe port that Hazelcast should listen on\nsteep.cluster.hazelcast.interfaces\nA list of IP address patterns specifying valid interfaces Hazelcast should bind to\nsteep.cluster.hazelcast.members\nA list of IP addresses (or hostnames) of Hazelcast cluster members\nsteep.cluster.hazelcast.tcpEnabled\ntrue if Hazelcast should use TCP to connect to other instances, false if it should use multicast\nDefault: false\nsteep.cluster.hazelcast.restoreMembersOnStartup.enabled\ntrue if Steep should try to load IP addresses of possibly still running VMs from its database during startup and add them to steep.cluster.hazelcast.members. This is useful if a Steep instance has crashed and should be reintegrated into an existing cluster when it’s back.\nDefault: false\nsteep.cluster.hazelcast.restoreMembersOnStartup.defaultPort\nIf steep.cluster.hazelcast.restoreMembersOnStartup.enabled is true, potential Hazelcast cluster members will be restored from database. This configuration item specifies on which Hazelcast port these members are listening.\nsteep.cluster.hazelcast.placementGroupName\nAn optional name specifying in which group this Hazelcast member should be placed. Steep uses distributed maps to share data between instances. Data in these maps is partitioned (i.e. distributed to the individual cluster members). In a large cluster, no member keeps all the data. Most nodes only keep a small fraction of the data (a partition).\nTo make sure data is not lost if a member goes down, Hazelcast uses backups to distribute copies of the data across the cluster. By specifying a placement group, you can control how Hazelcast distributes these backups. Hazelcast will always prefer creating backups in a group that does not own the data so that if all members of a group go down, the other group still has all the backup data.\nExamples for sensible groups are racks, data centers, or availability zones.\nFor more information, see the following links:\n * https://docs.hazelcast.com/hazelcast/5.1/architecture/data-partitioning\n * https://docs.hazelcast.com/hazelcast/5.1/clusters/partition-group-configuration\n * https://docs.hazelcast.com/hazelcast/5.1/data-structures/backing-up-maps\nNote that if you configure a placement group name, all members in your cluster must also have a placement group name. Otherwise, you will receive an exception about mismatching configuration on startup.\nsteep.cluster.hazelcast.liteMember\ntrue if this instance should be a Hazelcast lite member. Lite members do not own any in-memory data. They are mainly used for compute-intensive tasks. With regard to Steep, an instance with a controller and a scheduler should not be a lite member, because these components heavily rely on internal state. A Steep instance that only contains an agent and therefore only executes services, however, could be a lite member. See the architecture section for more information about these components.\nYour cluster cannot consist of only lite members. Otherwise, it is not able to maintain internal state at all.\nNote that since lite members cannot keep data, they are not suitable to keep backups either. See steep.cluster.hazelcast.placementGroupName for more information. For reasons of reliability, a cluster should contain at least three full (i.e. non-lite) members.\nsteep.cluster.lookupOrphansInterval\nThe interval at which Steep’s main thread looks for orphaned entries in its internal remote agent registry (specified as a duration). Such entries may (very rarely) happen if there is a network failure during deregistration of an agent. You normally do not have to change this configuration.\nDefault: 5m"},{"slug":"http-configuration","body":"steep.http.enabled\ntrue if the HTTP interface should be enabled\nDefault: true\nsteep.http.host\nThe host to bind the HTTP server to\nDefault: localhost\nsteep.http.port\nThe port the HTTP server should listen on\nDefault: 8080\nsteep.http.postMaxSize\nThe maximum size of HTTP POST bodies in bytes\nDefault: 1048576 (1 MB)\nsteep.http.basePath\nThe path where the HTTP endpoints and the web-based user interface should be mounted\nDefault: \"\" (empty string, i.e. no base path)\nsteep.http.allowRoutes\nA regular expression specifying a whitelist of enabled HTTP routes. Non-matching routes will be disabled. For example, the expression /processchains.* enables all endpoints starting with /processchains but disables all others.\nDefault: .* (all routes are enabled)\nsteep.http.cors.enable\ntrue if Cross-Origin Resource Sharing (CORS) should be enabled\nDefault: false\nsteep.http.cors.allowOrigin\nA regular expression specifying allowed CORS origins. Use * to allow all origins.\nDefault: \"$.\" (match nothing by default)\nsteep.http.cors.allowCredentials\ntrue if the Access- Control- Allow- Credentials response header should be returned.\nDefault: false\nsteep.http.cors.allowHeaders\nA string or an array indicating which header field names can be used in a request.\nsteep.http.cors.allowMethods\nA string or an array indicating which HTTP methods can be used in a request.\nsteep.http.cors.exposeHeaders\nA string or an array indicating which headers are safe to expose to the API of a CORS API specification.\nsteep.http.cors.maxAgeSeconds\nThe number of seconds the results of a preflight request can be cached in a preflight result cache."},{"slug":"controller-configuration","body":"steep.controller.enabled\ntrue if the controller should be enabled. Set this value to false if your Steep instance does not have access to the shared database.\nDefault: true\nsteep.controller.lookupInterval\nThe interval at which the controller looks for accepted submissions, specified as a duration.\nDefault: 2s\nsteep.controller.lookupMaxErrors\nThe maximum number of consecutive errors (e.g. database connection issues) to tolerate when looking up the status of process chains of a running submission. If there are more errors, the submission will be aborted.\nDefault: 5\nsteep.controller.lookupOrphansInterval\nThe interval at which the controller looks for orphaned running submissions (i.e. submissions that are in the status RUNNING but that are currently not being processed by any controller instance), specified as a duration. If Steep finds such a submission it will try to resume it.\nDefault: 5m\nsteep.controller.lookupOrphansInitialDelay\nThe time the controller should wait after startup before it looks for orphaned running submissions for the first time (specified as a duration). This property is useful if you want to implement a rolling update from one Steep instance to another.\nDefault: 0s"},{"slug":"scheduler-configuration","body":"steep.scheduler.enabled\ntrue if the scheduler should be enabled. Set this value to false if your Steep instance does not have access to the shared database.\nDefault: true\nsteep.scheduler.lookupInterval\nThe interval at which the scheduler looks for registered process chains, specified as a duration.\nDefault: 20s\nsteep.scheduler.lookupOrphansInterval\nThe interval at which the scheduler looks for orphaned running process chains (i.e. process chains that are in the status RUNNING but that are currently not being processed by any scheduler instance), specified as a duration. Note that the scheduler also always looks for orphaned process chains when it detects that another scheduler instance has just left the cluster (regardless of the configured interval).\nDefault: 5m\nsteep.scheduler.lookupOrphansInitialDelay\nThe time the scheduler should wait after startup before it looks for orphaned running process chains for the first time (specified as a duration). This property is useful if you want to implement a rolling update from one Steep instance to another. Note that the scheduler also looks for orphaned process chains when another scheduler instance has just left the cluster, even if the initial delay has not passed by yet.\nDefault: 0s"},{"slug":"agent-configuration","body":"steep.agent.enabled\ntrue if this Steep instance should be able to execute process chains (i.e. if one or more agents should be deployed)\nDefault: true\nsteep.agent.instances\nThe number of agents that should be deployed within this Steep instance (i.e. how many executables the Steep instance can run in parallel)\nDefault: 1\nsteep.agent.id\nUnique identifier for the first agent instance deployed. Subsequent agent instances will have a consecutive number appended to their IDs.\nDefault: (an automatically generated unique ID)\nsteep.agent.capabilities\nList of capabilities that the agents provide\nDefault: [] (empty list)\nsteep.agent.autoShutdownTimeout\nThe time any agent instance can remain idle until Steep shuts itself down gracefully (specified as a duration). By default, this value is 0s, which means Steep never shuts itself down.\nDefault: 0s\nsteep.agent.busyTimeout\nThe time that should pass before an idle agent decides that it is not busy anymore (specified as a duration). Normally, the scheduler allocates an agent, sends it a process chain, and then deallocates it after the process chain execution has finished. This value is important if the scheduler crashes while the process chain is being executed and does not deallocate the agent anymore. In this case, the agent deallocates itself after the configured time has passed.\nDefault: 1m\nsteep.agent.outputLinesToCollect\nThe number of output lines to collect at most from each executed service (also applies to error output)\nDefault: 100"},{"slug":"runtime-settings","body":"steep.runtimes.docker.env\nAdditional environment variables that will be passed to containers created by the Docker runtime\nExample: [\"key=value\", \"foo=bar\"]\nDefault: [] (empty list)\nsteep.runtimes.docker.volumes\nAdditional volume mounts to be passed to the Docker runtime\nExample: [\"/data:/data\"]\nDefault: [] (empty list)"},{"slug":"database-connection","body":"steep.db.driver\nThe database driver\nValid values: inmemory, postgresql, mongodb\nDefault: inmemory\nsteep.db.url\nThe database URL\nsteep.db.username\nThe database username (only used by the postgresql driver)\nsteep.db.password\nThe database password (only used by the postgresql driver)\nsteep.db.connectionPool.maxSize\nThe maximum number of connections to keep open (i.e. to keep in the connection pool)\nsteep.db.connectionPool.maxIdleTime\nThe maximum time an idle connection should be kept in the connection pool before it is closed"},{"slug":"cloud-connection","body":"steep.cloud.enabled\ntrue if Steep should connect to a cloud to acquire remote agents on demand\nDefault: false\nsteep.cloud.driver\nDefines which cloud driver to use\nValid values: openstack (see the OpenStack cloud driver for more information)\nsteep.cloud.createdByTag\nA metadata tag that should be attached to virtual machines to indicate that they have been created by Steep\nsteep.cloud.syncInterval\nThe time that should pass before the cloud manager synchronizes its internal state with the cloud again, specified as a duration.\nDefault: 2m\nsteep.cloud.keepAliveInterval\nThe time that should pass before the cloud manager sends keep-alive messages to a minimum of remote agents again (so that they do not shut down themselves), specified as a duration. See minVMs property of the setups data model.\nDefault: 30s\nsteep.cloud.setups.file\nThe path to the file that describes all available setups. See setups.yaml.\nsteep.cloud.setups.creation.retries\nA retry policy that specifies how many attempts should be made to create a VM from a certain setup (if creation fails) as well as possible (exponential) delays between those attempts.\nDEFAULT:\nsteep.cloud.setups.lockAfterRetries\nWhen the maximum number of attempts to create a VM from a certain setup has been reached (see steep.cloud.setups.creation.retries), the setup will be locked and no other VM with this setup will be created. This parameter defines how long it will be locked, specified as a duration.\nDefault: 20m\nsteep.cloud.timeouts.sshReady\nThe maximum time the cloud manager should try to log in to a new VM via SSH (specified as a duration). The cloud manager will make a login attempt every 2 seconds until it is successful or until the maximum number of seconds have passed, in which case it will destroy the VM.\nDefault: 5m\nsteep.cloud.timeouts.agentReady\nThe maximum time the cloud manager should wait for an agent on a new VM to become available (i.e. how long a new Steep instance may take to register with the cluster) before it destroys the VM again (specified as a duration).\nDefault: 5m\nsteep.cloud.timeouts.createVM\nThe maximum time that creating a VM may take before it is aborted with an error (specified as a duration).\nDefault: 5m\nsteep.cloud.timeouts.destroyVM\nThe maximum time that destroying a VM may take before it is aborted with an error (specified as a duration).\nDefault: 5m\nsteep.cloud.agentPool\nAn array of agent pool parameters describing how many remote agents the cloud manager should keep in its pool how many it is allowed to create for each given set of capabilities.\nDefault: [] (empty list)"},{"slug":"openstack-cloud-driver","body":"steep.cloud.openstack.endpoint\nOpenStack authentication endpoint\nsteep.cloud.openstack.username\nOpenStack username used for authentication\nsteep.cloud.openstack.password\nOpenStack password used for authentication\nsteep.cloud.openstack.domainName\nOpenStack domain name used for authentication\nsteep.cloud.openstack.projectId\nThe ID of the OpenStack project to which to connect. Either this configuration item or steep.cloud.openstack.projectName must be set but not both at the same time.\nsteep.cloud.openstack.projectName\nThe name of the OpenStack project to which to connect. This configuration item will be used in combination with steep.cloud.openstack.domainName if steep.cloud.openstack.projectId is not set.\nsteep.cloud.openstack.networkId\nThe ID of the OpenStack network to attach new VMs to\nsteep.cloud.openstack.usePublicIp\ntrue if new VMs should have a public IP address\nDefault: false\nsteep.cloud.openstack.securityGroups\nThe OpenStack security groups that should be attached to new VMs.\nDefault: [] (empty list)\nsteep.cloud.openstack.keypairName\nThe name of the keypair to deploy to new VMs. The keypair must already exist in OpenStack."},{"slug":"ssh-connection-to-vms","body":"steep.cloud.ssh.username\nUsername for SSH access to VMs. Can be overridden by the sshUsername property in each setup. May even be null if all setups define their own username.\nsteep.cloud.ssh.privateKeyLocation\nLocation of a private key to use for SSH"},{"slug":"log-configuration","body":"steep.logs.level\nThe default log level for all loggers (console as well as file-based)\nValid values: TRACE, DEBUG, INFO, WARN, ERROR, OFF.\nDefault: DEBUG\nsteep.logs.main.enabled\ntrue if logging to the main log file should be enabled\nDefault: false\nsteep.logs.main.logFile\nThe name of the main log file\nDefault: logs/steep.log\nsteep.logs.main.dailyRollover.enabled\ntrue if main log files should be renamed every day. The file name will be based on steep.logs.main.logFile and the file’s date in the form YYYY-MM-DD (e.g. steep.2020-11-19.log)\nDefault: true\nsteep.logs.main.dailyRollover.maxDays\nThe maximum number of days’ worth of main log files to keep\nDefault: 7\nsteep.logs.main.dailyRollover.maxSize\nThe total maximum size of all main log files in bytes. Oldest log files will deleted when this size is reached.\nDefault: 104857600 (100 MB)\nsteep.logs.processChains.enabled\ntrue if the output of process chains should be logged separately to disk. The output will still also appear on the console and in the main log file (if enabled), but there, it’s not separated by process chain. This feature is useful if you want to record the output of individual process chains and make it available through the process chain logs endpoint.\nDefault: false\nsteep.logs.processChains.path\nThe path where process chain logs will be stored. Individual files will will be named after the ID of the corresponding process chain (e.g. aprsqz6d5f4aiwsdzbsq.log). If a process chain has been executed more than once (for example, due to a retry), the file name will include the run number (e.g. aprsqz6d5f4aiwsdzbsq.2.log).\nDefault: logs/processchains\nsteep.logs.processChains.groupByPrefix\nSet this configuration item to a value greater than 0 to group process chain log files by prefix in subdirectories under the directory configured through steep.logs.processChains.path. For example, if this configuration item is set to 3, Steep will create a separate subdirectory for all process chains whose ID starts with the same three characters. The name of this subdirectory will be these three characters. The process chains apomaokjbk3dmqovemwa and apomaokjbk3dmqovemsq will be put into a subdirectory called apo, and the process chain ao344a53oyoqwhdelmna will be put into ao3. Note that in practice, 3 is a reasonable value, which will create a new directory about every day. A value of 0 disables grouping.\nDefault: 0"},{"slug":"garbage-collector-configuration","body":"steep.garbageCollector.enabled\ntrue if the garbage collector should be enabled. The garbage collector runs in the background and removes outdated objects from the database at the interval specified with steep.garbageCollector.cron\nDefault: false\nsteep.garbageCollector.cron\nA UNIX-like cron expression specifying the interval at which the garbage collector should be executed. Cron expressions consist of six required fields and one optional field separated by a white space:\nSECONDS MINUTES HOURS DAY-OF-MONTH MONTH DAY-OF-WEEK [YEAR].\nUse an asterisk * to specify all values (e.g. every second or every minute). Use a question mark ? for DAY-OF-MONTH or DAY-OF-WEEK to specify no value (only one of DAY-OF-MONTH or DAY-OF-WEEK can be specified at the same time). Use a slash / to specify increments (e.g. */5 for every 5 minutes).\nMore information about the format can be found in the javadoc of the org.quartz.CronExpression class.\nExample: 0 0 0 * * ? (daily at 12am)\nsteep.garbageCollector.retention.submissions\nThe maximum time a submission should be kept in the database after it has finished (regardless of whether it was successful or not). The time can be specified as a human-readable duration.\nDefault: null (submissions will be kept indefinitely)\nsteep.garbageCollector.retention.vms\nThe maximum time a VM should be kept in the database after it has been destroyed (regardless of its status). The time can be specified as a human-readable duration.\nDefault: null (VMs will be kept indefinitely)"},{"slug":"cache-configuration","body":"steep.cache.plugins.enabled\ntrue if the persistent compiled plugin cache should be enabled. Steep updates this cache on startup when it has first compiled a plugin script or when it detects that a previously compiled script has changed. On subsequent startups, Steep can utilize the cache to skip compilation of known plugins and, therefore, to reduce startup time.\nDefault: false\nsteep.cache.plugins.path\nThe path to a directory where Steep should store compiled plugin scripts if the persistent compiled plugin cache is enabled (see steep.cache.plugins.enabled).\nDefault: .cache/plugins"},{"slug":"agent-pool-parameters","body":"Steep’s cloud manager component is able to create virtual machines and deploy remote agent instances to it. The cloud manager keeps every remote agent created in a pool. Use agent pool parameters to define a minimum and maximum number of instances per provided capability set.\nPropertyTypeDescription\ncapabilities\nA set of strings spec­i­fy­ing ca­pa­bil­i­ties that a remote agent must provide so these parameters apply to it\nmin\nAn optional minimum number of remote agents that the cloud manager should create with the given capabilities\nmax\nAn optional maximum number of remote agents that the cloud manager is allowed to create with the given capabilities\n"},{"slug":"steepyaml","body":"Configuration\nThe file steep.yaml contains the main configuration of Steep. This page describes all configuration keys and values you can set.\nNote that keys are specified using the dot notation. You can use them as they are given here or use YAML notation instead. For example, the following configuration item\nis identical to:\nYou may override items in your configuration file with environment variables. This is particularly useful if you are using Steep inside a Docker container. The environment variables use a slightly different naming scheme. All variables are in capital letters and dots are replaced by underscores. For example, the configuration key steep.http.host becomes STEEP_HTTP_HOST and steep.cluster.eventBus.publicPort becomes STEEP_CLUSTER_EVENTBUS_PUBLICPORT. You may use YAML syntax to specify environment variable values. For example, the array steep.agent.capabilities can be specified as follows:\n"},{"slug":"setupsyaml","body":"Configuration\nThe configuration file setups.yaml contains an array of setup objects that Steep’s cloud manager component uses to create new virtual machines and to deploy remote agents to it.\nNote: The path to the setups configuration file can be configured with the item steep.setups in Steep’s general configuration.\nsetups.yaml\n"},{"slug":"submission-status","body":"The following table shows the statuses a submission can have:\nStatusDescription\nACCEPTED\nThe submission has been accepted by Steep but execution has not started yet\nRUNNING\nThe submission is currently being executed\nCANCELLED\nThe submission was cancelled\nSUCCESS\nThe execution of the submission finished successfully\nPARTIAL_SUCCESS\nThe submission was executed completely but one or more process chains failed\nERROR\nThe execution of the submission failed"},{"slug":"submissions","body":"Data models\nA submission is created when you submit a workflow through the /workflows endpoint. It contains information about the workflow execution such as the start and end time as well as the current status.\nPropertyTypeDescription\nid\nUnique submission identifier\nname\nAn optional human-readable submission name. The value is derived from the submitted workflow’s name if it has any.\nworkflow\nThe submitted workflow\npriority\nA priority used during scheduling. Process chains generated from submissions with higher priorities will be scheduled before those with lower priorities. Negative values are allowed. The value is derived from the submitted workflow but can be overridden. The submission’s priority always takes precedence over the workflow’s priority when generating process chains.\nstartTime\nAn ISO 8601 timestamp denoting the date and time when the workflow execution was started. May be null if the execution has not started yet.\nendTime\nAn ISO 8601 timestamp denoting the date and time when the workflow execution finished. May be null if the execution has not finished yet.\nstatus\nThe current status of the submission\nrequiredCapabilities\nA set of strings specifying capabilities a host system must provide to be able to execute this workflow. See also setups.\nsource\nThe original, unaltered workflow source as it was submitted through the /workflows endpoint. May be null if the workflow was not submitted through the endpoint or if the source is unavailable.\nrunningProcessChains\nThe number of process chains currently being executed\npausedProcessChains\nThe number of process chains whose execution is currently paused\ncancelledProcessChains\nThe number of process chains that have been cancelled\nsucceededProcessChains\nThe number of process chains that have finished successfully\nfailedProcessChains\nThe number of process chains whose execution has failed\ntotalProcessChains\nThe current total number of process chains in this submission. May increase during execution when new process chains are generated.\nresults\nIf status is SUCCESS or PARTIAL_SUCCESS, this property contains the list of workflow result files grouped by their output variable ID. Otherwise, it is null.\nerrorMessage\nIf status is ERROR, this property contains a human-readable error message. Otherwise, it is null.\n"},{"slug":"timeout-policies","body":"A timeout policy defines how long a service or an executable may run before it is automatically cancelled or aborted (with an error). Timeout policies can be specified with the maxInactivity, maxRuntime and deadline attributes, either per service in the service metadata or per executable action in the workflow.\nA timeout policy is either a string or an object. If it is a string, it represents a duration specifying a maximum amount of time until the execution is cancelled.\nIf specified as an object, the timeout policy has the following properties:\nPropertyTypeDescription\ntimeout\nduration\nThe maximum amount of time that may pass until the execution is cancelled or aborted.\nerrorOnTimeout\ntrue if an execution that is aborted due to a timeout should lead to an error (i.e. if the process chain’s status should be set to ERROR). false if it should just be cancelled (process chain status CANCELLED). By default, the execution will be cancelled.\nMultiple timeout policies can be combined. For example, a service may be cancelled after 5 minutes of inactivity and aborted with an error if its total execution takes longer than 1 hour.\n"},{"slug":"retry-policies","body":"A retry policy specifies how often the execution of a workflow action should be retried in case of an error. Retry policies can be specified per service in the service metadata or per executable action in the workflow.\nPropertyTypeDescription\nmaxAttempts\nThe maximum number of attempts to perform. This includes the initial attempt. For example, a value of 3 means 1 initial attempt and 2 retries. The default value is 1. A value of -1 means an unlimited (infinite) number of attempts. 0 means there will be no attempt at all (the service or action will be skipped).\ndelay\nduration\nThe amount of time that should pass between two attempts. The default is 0, which means the operation will be retried immediately.\nexponentialBackoff\nA factor for an exponential backoff (see description below)\nmaxDelay\nduration\nThe maximum amount of time that should pass between two attempts. Only applies if exponentialBackoff is larger than 1. By default, there is no upper limit.\nEXPONENTIAL BACKOFF:\nThe exponential backoff factor can be used to gradually increase the delay. The actual delay between two attempts will be calculated as follows:\nFor example, if delay equals 1s, exponentialBackoff equals 2, and maxDelay equals 10s, the following actual delays will apply:\n * Delay after attempt 1:\n   \n   min(1s * pow(2, 0), 10s) = 1s\n * Delay after attempt 2:\n   \n   min(1s * pow(2, 1), 10s) = 2s\n * Delay after attempt 3:\n   \n   min(1s * pow(2, 2), 10s) = 4s\n * Delay after attempt 4:\n   \n   min(1s * pow(2, 3), 10s) = 8s\n * Delay after attempt 5:\n   \n   min(1s * pow(2, 4), 10s) = 10s\n * Delay after attempt 6:\n   \n   min(1s * pow(2, 4), 10s) = 10s\nThe default value is 1, which means there is no backoff and the actual delay always equals the specified one.\n"},{"slug":"durations","body":"A duration consists of one or more number/unit pairs possibly separated by whitespace characters. Supported units are:\n * milliseconds, millisecond, millis, milli, ms\n * seconds, second, secs, sec, s\n * minutes, minute, mins, min, m\n * hours, hour, hrs, hr, h\n * days, day, d\nNumbers must be positive integers. The default unit is milliseconds\nExamples:\n"},{"slug":"timeouts-and-retries","body":"Data models\nThis page describes data models that control how long a workflow may take until it is cancelled or aborted (timeout policies) and what should happen if a timeout runs into an error (retry policies).\nTime-based values in Steep’s data models are always described using human-readable durations."},{"slug":"tutorial-segment-aerial-images","body":"Introduction\nTODO"},{"slug":"using-a-template-engine","body":"Advanced configuration topics\nSteep contains a template engine that allows you to dynamically generate content for YAML-based configuration files (steep.yaml, setups.yaml, services/services.yaml, etc.) at startup.\nYou have to explicitly enable this feature by adding front matter to your YAML file and setting the attribute template to true:\nSteep uses Pebble Templates to compile the configuration files. Please refer to their website for a full documentation on the tags, functions, and filters you can use.\nWithin your template, you may access the following variables:\nVariableDescription\nenv\nA dictionary of environment variables. Use subscript notation ([]) to access its contents. Example: {{ env[\"PATH\"] }}\nconfig\nA dictionary of configuration properties. This variable is not available in steep.yaml (or any override configuration file). Use subscript notation ([]) to access its contents. Example: {{ config[\"steep.cluster.hazelcast.publicAddress\"] }}\nHere is a full example of a setups.yaml file that uses the templating feature to create two setups with the same parameters, an image name from an environment variable, but different availability zones:\n"},{"slug":"using-yaml-anchors","body":"Advanced configuration topics\nConfiguration files for setups (setups.yaml) and service metadata (services/services.yaml) often contain repeated information (e.g. two setups might offer the same capabilities). You can use YAML anchors to simplify your configuration files.\nThe following example shows two services sharing a parameter seconds. The parameter is defined once for the sleep service and then reused in the docker_sleep service through the YAML anchor sleep_seconds.\n"},{"slug":"variables","body":"A variable holds a value for inputs and outputs of processing services. It can be defined (inputs) or undefined (outputs). Defined values are immutable. Undefined variables will be assigned a value by Steep during workflow execution.\nVariables are also used to link two services together and to define the data flow in the workflow graph. For example, if the output parameter of a service A refers to a variable V, and the input parameter of service B refers to the same variable, Steep will first execute A to determine the value of V and then execute B.\nPropertyTypeDescription\nid\nA unique variable identifier\nvalue\nThe variable’s value or null if the variable is undefined\n"},{"slug":"actions","body":"There are two types of actions in a workflow: execute actions and for-each actions. They are differentiated by their type attribute.\nAn execute action instructs Steep to execute a certain service with given inputs and outputs.\nPropertyTypeDescription\nid\nAn optional string uniquely identifying the action within the workflow. If not given, a random identifier will be generated.\ntype\nThe type of the action. Must be execute.\nservice\nThe ID of the service to execute\ninputs\nAn array of input parameters\noutputs\nAn array of output parameters\ndependsOn\nA list of identifiers of actions this action needs to finish first before it is ready to be executed. Note that Steep is able to identify dependencies between actions itself based on outputs and inputs, so this attribute is normally not needed. However, it may be useful if a preceding action does not have an output parameter or if the depending action does not have an input parameter. Execute actions may depend on other execute actions but also on for-each actions and vice versa.\nretries\nAn optional retry policy specifying how often this action should be retried in case of an error. Overrides any default retry policy defined in the service metadata.\nmaxInactivity\nduration or object\nAn optional duration or timeout policy that defines how long the execution of the service can take without producing any output (i.e. without writing anything to the standard output and error streams) before it is automatically cancelled or aborted. Can be combined with maxRuntime and deadline (see below). Overrides any default inactivity timeout defined in the service metadata. Note that a service cancelled due to inactivity is still subject to any configured retry policy, which means its execution may be retried even if one attempt timed out. If you want to cancel a long-running service immediately even if there is a retry policy configured, use a deadline.\nmaxRuntime\nduration or object\nAn optional duration or timeout policy that defines how long the execution of the service can take before it is automatically cancelled or aborted, even if the service regularly writes to the standard output and error streams. Can be combined with maxInactivity (see above) and deadline (see below). Overrides any default maximum runtime defined in the service metadata. Note that a service cancelled due to a too long runtime is still subject to any configured retry policy, which means its execution may be retried even if one attempt timed out. If you want to cancel a long-running service immediately even if there is a retry policy configured, use a deadline.\ndeadline\nduration or object\nAn optional duration or timeout policy that defines how long the execution of the service can take at all (including all retries and their associated delays) until it is cancelled or aborted. Can be combined with maxInactivity and maxRuntime (see above). Overrides any default deadline defined in the service metadata.\nA for-each action has an input, a list of sub-actions, and an output. It clones the sub-actions as many times as there are items in its input, executes the actions, and then collects the results in the output.\nAlthough the action is called ‘for-each’, the execution order of the sub-actions is undefined (i.e. the execution is non-sequential and non-deterministic). Instead, Steep always tries to execute as many sub-actions as possible in parallel.\nFor-each actions may contain execute actions but also nested for-each actions.\nPropertyTypeDescription\nid\nAn optional string uniquely identifying the action within the workflow. If not given, a random identifier will be generated.\ntype\nThe type of the action. Must be for.\ninput\nThe ID of a variable containing the items to which to apply the sub-actions\nenumerator\nThe ID of a variable that holds the current value from input for each iteration\noutput\nThe ID of a variable that will collect output values from all iterations (see yieldToOutput)\ndependsOn\nA list of identifiers of actions this action needs to finish first before it is ready to be executed. Note that Steep is able to identify dependencies between actions itself based on outputs and inputs, so this attribute is normally not needed. However, it may be useful if a preceding action does not have an output parameter or if the depending action does not have an input parameter. For-each actions may depend on execute actions but also on other for-each actions and vice versa.\nactions\nAn array of sub-actions to execute in each iteration\nyieldToOutput\nThe ID of a sub-action’s output variable whose value should be appended to the for-each action’s output\nyieldToInput\nThe ID of a sub-action’s output variable whose value should be appended to the for-each action’s input to generate further iterations\nThis data model represents inputs and generic parameters of execute actions.\nPropertyTypeDescription\nid\nThe ID of the parameter as defined in the service metadata\nvar\nThe ID of a variable that holds the value for this parameter (required if value is not given)\nvalue\nThe parameter value (required if var is not given)\nNote: Either var or value must be given but not both!\nOutput parameters of execute actions have additional properties compared to inputs.\nPropertyTypeDescription\nid\nThe ID of the parameter as defined in the service metadata\nvar\nThe ID of a variable to which Steep will assign the generated name of the output file. This variable can then be used, for example, as an input parameter of a subsequent action.\nprefix\nAn optional string to prepend to the generated name of the output file. For example, if Steep generates the name \"name123abc\" and the prefix is \"my/dir/\", the output filename will be \"my/dir/name123abc\". Note that the prefix must end with a slash if you want to create a directory. The output filename will be relative to the configured temporary directory or output directory (depending on the store property). You may even specify an absolute path: if the generated name is \"name456fgh\" and the prefix is \"/absolute/dir/\", the output filename will be \"/absolute/dir/name456fgh\".\nstore\nIf this property is true, Steep will generate an output filename that is relative to the configured output directory instead of the temporary directory. The default value is false.\n"},{"slug":"execute-actions","body":"An execute action instructs Steep to execute a certain service with given inputs and outputs.\nPropertyTypeDescription\nid\nAn optional string uniquely identifying the action within the workflow. If not given, a random identifier will be generated.\ntype\nThe type of the action. Must be execute.\nservice\nThe ID of the service to execute\ninputs\nAn array of input parameters\noutputs\nAn array of output parameters\ndependsOn\nA list of identifiers of actions this action needs to finish first before it is ready to be executed. Note that Steep is able to identify dependencies between actions itself based on outputs and inputs, so this attribute is normally not needed. However, it may be useful if a preceding action does not have an output parameter or if the depending action does not have an input parameter. Execute actions may depend on other execute actions but also on for-each actions and vice versa.\nretries\nAn optional retry policy specifying how often this action should be retried in case of an error. Overrides any default retry policy defined in the service metadata.\nmaxInactivity\nduration or object\nAn optional duration or timeout policy that defines how long the execution of the service can take without producing any output (i.e. without writing anything to the standard output and error streams) before it is automatically cancelled or aborted. Can be combined with maxRuntime and deadline (see below). Overrides any default inactivity timeout defined in the service metadata. Note that a service cancelled due to inactivity is still subject to any configured retry policy, which means its execution may be retried even if one attempt timed out. If you want to cancel a long-running service immediately even if there is a retry policy configured, use a deadline.\nmaxRuntime\nduration or object\nAn optional duration or timeout policy that defines how long the execution of the service can take before it is automatically cancelled or aborted, even if the service regularly writes to the standard output and error streams. Can be combined with maxInactivity (see above) and deadline (see below). Overrides any default maximum runtime defined in the service metadata. Note that a service cancelled due to a too long runtime is still subject to any configured retry policy, which means its execution may be retried even if one attempt timed out. If you want to cancel a long-running service immediately even if there is a retry policy configured, use a deadline.\ndeadline\nduration or object\nAn optional duration or timeout policy that defines how long the execution of the service can take at all (including all retries and their associated delays) until it is cancelled or aborted. Can be combined with maxInactivity and maxRuntime (see above). Overrides any default deadline defined in the service metadata.\n"},{"slug":"for-each-actions","body":"A for-each action has an input, a list of sub-actions, and an output. It clones the sub-actions as many times as there are items in its input, executes the actions, and then collects the results in the output.\nAlthough the action is called ‘for-each’, the execution order of the sub-actions is undefined (i.e. the execution is non-sequential and non-deterministic). Instead, Steep always tries to execute as many sub-actions as possible in parallel.\nFor-each actions may contain execute actions but also nested for-each actions.\nPropertyTypeDescription\nid\nAn optional string uniquely identifying the action within the workflow. If not given, a random identifier will be generated.\ntype\nThe type of the action. Must be for.\ninput\nThe ID of a variable containing the items to which to apply the sub-actions\nenumerator\nThe ID of a variable that holds the current value from input for each iteration\noutput\nThe ID of a variable that will collect output values from all iterations (see yieldToOutput)\ndependsOn\nA list of identifiers of actions this action needs to finish first before it is ready to be executed. Note that Steep is able to identify dependencies between actions itself based on outputs and inputs, so this attribute is normally not needed. However, it may be useful if a preceding action does not have an output parameter or if the depending action does not have an input parameter. For-each actions may depend on execute actions but also on other for-each actions and vice versa.\nactions\nAn array of sub-actions to execute in each iteration\nyieldToOutput\nThe ID of a sub-action’s output variable whose value should be appended to the for-each action’s output\nyieldToInput\nThe ID of a sub-action’s output variable whose value should be appended to the for-each action’s input to generate further iterations\n"},{"slug":"parameters","body":"This data model represents inputs and generic parameters of execute actions.\nPropertyTypeDescription\nid\nThe ID of the parameter as defined in the service metadata\nvar\nThe ID of a variable that holds the value for this parameter (required if value is not given)\nvalue\nThe parameter value (required if var is not given)\nNote: Either var or value must be given but not both!\n"},{"slug":"output-parameters","body":"Output parameters of execute actions have additional properties compared to inputs.\nPropertyTypeDescription\nid\nThe ID of the parameter as defined in the service metadata\nvar\nThe ID of a variable to which Steep will assign the generated name of the output file. This variable can then be used, for example, as an input parameter of a subsequent action.\nprefix\nAn optional string to prepend to the generated name of the output file. For example, if Steep generates the name \"name123abc\" and the prefix is \"my/dir/\", the output filename will be \"my/dir/name123abc\". Note that the prefix must end with a slash if you want to create a directory. The output filename will be relative to the configured temporary directory or output directory (depending on the store property). You may even specify an absolute path: if the generated name is \"name456fgh\" and the prefix is \"/absolute/dir/\", the output filename will be \"/absolute/dir/name456fgh\".\nstore\nIf this property is true, Steep will generate an output filename that is relative to the configured output directory instead of the temporary directory. The default value is false.\n"},{"slug":"retry-policy-defaults","body":"A default retry policy that should be used within a workflow unless a more specific retry policy is defined elsewhere.\nPropertyTypeDescription\nprocessChains\nAn optional default retry policy that should be applied to every generated process chain\n"},{"slug":"workflows","body":"Data models\nThe main components of the workflow model are variables and actions. Use variables to specify input files and parameters for your processing services. Variables for output files must not have a value. The names of output files will be generated by Steep during workflow execution.\nPropertyTypeDescription\napi\nThe API (or data model) version. Should be 4.6.0.\nname\nAn optional human-readable workflow name\npriority\nA priority used during scheduling. Process chains generated from workflows with higher priorities will be scheduled before those with lower priorities. Negative values are allowed. The default value is 0.\nretries\nDefault retry policies that should be used within the workflow unless more specific retry policies are defined elsewhere.\nvars\nAn array of variables\nactions\nAn array of actions that make up the workflow\nSee the section on example workflows."},{"slug":"vm-status","body":"The following table shows the statuses a VM can have:\nStatusDescription\nCREATING\nThe VM is currently being created\nPROVISIONING\nThe VM has been created and is currently being provisioned (i.e. provisioning scripts defined in the VM’s setup are being executed and the Steep agent is being deployed)\nRUNNING\nThe VM has been created and provisioned successfully. It is currently running and registered as a remote agent.\nLEFT\nThe remote agent on this VM has left. It will be destroyed eventually.\nDESTROYING\nThe VM is currently being destroyed\nDESTROYED\nThe VM has been destroyed\nERROR\nThe VM could not be created, provisioned, or it failed otherwise. See the VM’s reason property for more information."},{"slug":"vms","body":"Data models\nThis data model describes virtual machines created by Steep’s cloud manager.\nPropertyTypeDescription\nid\nA unique VM identifier\nexternalId\nAn identifier generated by the cloud platform\nipAddress\nThe VM’s IP address\nsetup\nThe setup used to create this VM\ncreationTime\nAn ISO 8601 timestamp denoting the date and time when the VM was created. This property is null if the VM has not been created yet.\nagentJoinTime\nAn ISO 8601 timestamp denoting the date and time when a Steep agent has been deployed to the VM and has joined the cluster. This property is null if the agent has not joined the cluster yet.\ndestructionTime\nAn ISO 8601 timestamp denoting the date and time when the VM was destroyed. This property is null if the VM has not been destroyed yet.\nstatus\nThe status of the VM\nreason\nThe reason why the VM has the current status (e.g. an error message if it has the ERROR status or a simple message indicating why it has been DESTROYED)"},{"slug":"web-based-user-interface","body":"Interfaces\nSteep has a web-based user interface that allows you to monitor the execution of running workflows, process chains, agents, and VMS, as well as to browse the database contents.\nStart Steep and visit any of its HTTP endpoints with your web browser to open the user interface.\nhttp://localhost:8080/workflows"}]